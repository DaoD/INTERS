"""
Templates for INTERS
"""

TASK_DESCRIPTIONS = {
    "query_description": "The query description task aims at describing documents potentially relevant to a user-provided query. Queries typically comprise keywords reflecting the user's information needs. The objective of the task is to describe the characteristics and content of documents that would be considered relevant to the queries, aiding in the understanding and retrieval of relevant information.",
    "query_expansion": "The query expansion task involves elaborating an original, brief query into a longer, more detailed version while preserving the original search intent. This process enhances the search engine's understanding of the user's needs, leading to more accurate and relevant document retrieval.",
    "query_reformulation": "The query reformulation task enhances user-input queries to be more explicit and comprehensible for search engines. It addresses omissions typical of user queries, which often exclude common sense or contextually implied information. The refined query, therefore, includes all necessary details to guide the search engine towards retrieving the most relevant documents.",
    "query_clarification": "The query clarification task addresses unclear or ambiguous user queries by asking for further details or providing clarification options. This process helps refine the query, resulting in clearer and more precise search terms for improved search engine results.",
    "query_subtopic_generation": "The query subtopic generation task addresses the ambiguity of web searches by identifying and presenting various aspects of the initial query. This approach aids search engines in understanding the query's breadth, leading to more diverse and relevant search results.",
    "query_matching": "The query matching task involves determining whether two queries or texts, despite differing in expression, convey the same meaning. This is crucial in search tasks where identifying synonymous queries can enhance the relevance and accuracy of results.",
    "query_suggestion": "In search sessions, users often input a series of queries to fulfill a specific information need. The query suggestion task aims to analyze these queries and associated search behaviors to understand the user's intent and predict the next likely query, thereby enhancing the search experience.",
    "query_intent_classification": "User queries can have various search intents, such as informational (seeking knowledge about a topic), transactional (aiming to purchase a product), or navigational (looking to find a specific website). Accurately discerning the type of intent behind a query is crucial for search engines to tailor and refine their results effectively.",
    "fact_verification": "The fact verification task is to assess whether a claim is supported or refuted by the given evidence. It requires a clear analysis of the relationship between the claim and the evidence, with careful examination to determine if there is enough information for making a judgment. It aids search engines in achieving a deeper comprehension of the documents.",
    "summarization": "The text summarization task seeks to create a concise summary of one or more lengthy documents, encapsulating all vital information while omitting extraneous details. The summary must accurately reflect the content of the original documents without introducing any new information. Achieving this necessitates a profound understanding of the documents, which can significantly enhance the performance of search engines by providing distilled, relevant content.",
    "reading_comprehension": "The reading comprehension task requires generating an answer to a question using the information from a given context. It necessitates a deep understanding of the text's context and semantics, enabling search engines to more accurately rank the relevance of retrieved documents based on this nuanced comprehension.",
    "conversational_qa": "Conversational question-answering involves responding to a series of interrelated questions based on a given context. As these questions might build upon shared information, some details may be implicitly understood rather than explicitly stated. By comprehensively understanding and analyzing this dialogue structure, search engines can enhance their interpretation of user queries and their connections to relevant documents, thereby improving result accuracy and relevance.",
    "retrieval": "In the reranking task, search engines must understand the relationship between the user's query, which may be keywords or a sentence, and the potential documents. The goal is to ensure that the most relevant documents, those that best cover the user's information needs, are ranked highest. This requires a nuanced understanding of both the query's intent and the content of the documents.",
}

HAS_REVERSE = {
    "query-description-gov2": [10, 11],
    "query-description-trec-robust": [10, 11],
    "query-description-trec-covid": [10, 11],
    "query-description-fire": [10, 11],
    "query-expansion-gov2": [10, 11],
    "query-expansion-trec-robust": [10, 11],
    "query-expansion-trec-covid": [10, 11],
    "query-expansion-fire": [10, 11],
    "query-expansion-query2doc": [10, 11],
    "query-expansion-trec-cast": [10, 11],
    "query-expansion-trec-web": [10, 11],
    "query-reformulation-codec":[],
    "query-reformulation-qrecc":[],
    "query-reformulation-canard":[],
    "query-reformulation-cast19": [],
    "query-reformulation-cast2x": [],
    "query-reformulation-gecor": [],
    "query-clarification-mimics": [],
    "query-clarification-mimics-duo": [],
    "query-clarification-clariq-fkw": [],
    "query-clarification-raocq": [],
    "query-subtopic-generation-trec-web": [],
    "query-matching-msrp": [],
    "qury-suggestion-aol": [],
    "query-intent-classification-orcas-i": [],
    "query-intent-classification-mantis": [],
    "query-intent-classification-trec-web": [5],
    "fact-verification-fever": [],
    "fact-verification-climate-fever": [],
    "fact-verification-scifact": [],
    "summarization-xsum": [10, 11],
    "summarization-cnn-dm": [10, 11], 
    "summarization-wikisum": [10, 11],
    "summarization-multi-news": [],
    "reading-comprehension-squad": [],
    "reading-comprehension-hotpot-qa": [],
    "reading-comprehension-ms-marco": [],
    "reading-comprehension-trivia-qa": [],
    "reading-comprehension-bool-q": [],
    "reading-comprehension-webglm-qa": [],
    "conversational-qa-coqa": [],
    "conversational-qa-quac": [],
    "general-retrieval-ms-marco": [],
    "biomedical-retrieval-trec-covid": [],
    "biomedical-retrieval-nfcorpus": [],
    "supporting-evidence-retrieval-nq": [],
    "supporting-evidence-retrieval-fiqa": [],
    "supporting-evidence-retrieval-hotpot-qa": [],
    "argument-retrieval-arguana": [],
    "argument-retrieval-touche": [],
    "duplicate-question-retrieval-cqadupstack": [],
    "duplicate-question-retrieval-quora": [],
    "entity-retrieval-dbpedia": [],
    "article-retrieval-scidocs": [],
    "fact-retrieval-climate-fever": [],
    "fact-retrieval-fever": [],
    "fact-retrieval-scifact": []
}

PATTERNS = {
    "query-description-gov2": [
        ("{title}\n\nWhat is the search target of the above query?", "{narrative}"),
        ("For the query \"{title}\", the search target is:", "{narrative}"),
        ("What type of thing is the query \"{title}\" searching for?", "{narrative}"),
        ("What is {title} about?", "{narrative}"),
        ("{title}\n\nGenerate an explanation about the above query's intent.", "{narrative}"),
        ("Given the query {title}, describe what kind of documents are relevant.", "{narrative}"),
        ("Describe some possible relevant documents about the search target {title}.", "{narrative}"),
        ("What is the search intent about the query {title}?", "{narrative}"),
        ("Describe the search intent of the given query \"{title}\".", "{narrative}"),
        ("Return the search intent for the following query:\n\n{title}", "{narrative}"),
        ("Referring to this description that describes the documents relevant to a query\n\n{narrative}\n\nplease infer the corresponding query.", "{title}"),
        ("{narrative}\n\nWhat is a possible query for these documents?", "{title}")
    ],
    "query-description-trec-robust": [
        ("{title}\n\nWhat kind of documents are relevant to the above query?", "{narrative}"),
        ("For the query \"{title}\", the relevant document is:", "{narrative}"),
        ("What type of documents is the query {title} intended to search for?", "{narrative}"),
        ("Tell me what is \"{title}\" seeking for?", "{narrative}"),
        ("{title}\n\nThe above query is in search of what kind of things?", "{narrative}"),
        ("Describe the document about the search target of the query \"{title}\".", "{narrative}"),
        ("The query {title} is aiming to find some documents. Describe the relevant documents:", "{narrative}"),
        ("Identify potential documents relevant to the query {title}.", "{narrative}"),
        ("{title}\n\nWhat is the query above attempting to discover?", "{narrative}"),
        ("Here's the query:\n{title}\nCould you suggest some documents that are relevant to this topic?", "{narrative}"), 
        ("Seeking for documents like\n\n{narrative}\n\nHow to formulate a query?", "{title}"),
        ("Give me a query to find such documents\n\n{narrative}", "{title}")
    ],
    "query-description-trec-covid": [
        ("{title}\n\nPlease identify the specific medical topic or subject inquired about in the above query.", "{narrative}"),
        ("For the topic of COVID-19 and the given query \"{title}\", describe the type of document that is relevant.", "{narrative}"),
        ("What is the intented document related to the query titled \"{title}\"?", "{narrative}"),
        ("Here is a query:\n\n{title}\n\nPlease indicate which kind of document is relevant.", "{narrative}"),
        ("{title}\n\nPlease describe relevant documents for the above topic in terms of covid.", "{narrative}"),
        ("Please describe some medical documents about the topic \"{title}\".", "{narrative}"),
        ("Please indicate some documents related to COVID-19 for the topic \"{title}\".", "{narrative}"),
        ("Provide the purpose or intent behind the query titled [{title}].", "{narrative}"),
        ("Which document has strong relevance to the covid topic \"{title}\"?", "{narrative}"),
        ("What kind of document does the topic \"{title}\" want to find?", "{narrative}"),
        ("Seeking for document about COVID-19\n\n{narrative}\n\nHow to construct a query?", "{title}"),
        ("{narrative}\n\nI'm looking for documents like this about COVID-19. Please provide me with a query.", "{title}")
    ],
    "query-description-fire": [
        ("{title}\n\nWhich document is related to the above query?", "{narrative}"),
        ("For the query \"{title}\", please indicate some documents that may be related to it.", "{narrative}"),
        ("What is the subject matter of the query \"{title}\"?", "{narrative}"),
        ("Please descibe relevant documents about the query {title}.", "{narrative}"),
        ("{title}\n\nWhat is the information sought in the above query?", "{narrative}"),
        ("Here is a query \"{title}\". Please indicate what kinds of documents are relevant.", "{narrative}"),
        ("Query: {title}\n\nWhat are the relevant documents?", "{narrative}"),
        ("Describe documents relevant to the query \"{title}\".", "{narrative}"),
        ("This ia a query \"{title}\". Analyze its search intent and indicate which kind of document is relevant.", "{narrative}"),
        ("Read the following query:\n\n{title}\n\nIndicate some relevant documents.", "{narrative}"),
        ("I need assistance in finding some documents:\n\n{narrative}\n\nPlease suggest a search query for me.", "{title}"),
        ("Looking for articles:\n\n{narrative}\n\nPlease give me a query.", "{title}")
    ],
    "query-expansion-gov2": [
        ("{title}\n\nWhat is this query asking?", "{description}"),
        ("Expand this query so that the retrieval performance can be enhanced:\n\n{title}", "{description}"),
        ("Based on this query: {title}, write a more detailed one.", "{description}"),
        ("Query Expansion:\n\n{title}", "{description}"),
        ("Make this query more specific:\n\n{title}", "{description}"),
        ("{title}\n\nRewrite the above query to improve search performance.", "{description}"),
        ("Could you please help me expand this query so that its intent is more clear?\n\n{title}", "{description}"),
        ("Try to extend this question to be more specific: {title}", "{description}"),
        ("Here is a question: {title} Can you expand it for searching?", "{description}"),
        ("This ia a query issued to search engine: {title}\nRewrite to describe its intent.", "{description}"),
        ("{description}\n\nBased on this intent description, you need to suggest a query.", "{title}"),
        ("The expanded version of query is\n\n{description}\n\nCondense it to a simple query.", "{title}")
    ],
    "query-expansion-trec-robust": [
        ("Given the following query, rewrite it to refine search.\n\n{title}", "{description}"),
        ("Enhance the following question for better retrieval results:\n\n{title}", "{description}"),
        ("You're presented with this initial query: {title}\nHow can you make it more targeted?", "{description}"),
        ("Refine this query:\n{title}", "{description}"),
        ("Transform this broad query into a more precise one:\n\n{title}", "{description}"),
        ("Read this query: {title}\nDescribe its underlying aim.", "{description}"),
        ("Could you provide a more detailed version of this question?\n\n{title}", "{description}"),
        ("Refine this search query to better capture the user's intent:\n\n{title}", "{description}"),
        ("Question:\n{title}\nExpanded Question: ", "{description}"),
        ("Analyze the following query:\n{title}\nRewrite it so that relevant documents are easier to find.", "{description}"),
        ("Simplify the expanded query:\n\n{description}\n\ninto a single question.", "{title}"),
        ("Formulate a brief question from the description:\n\n{description}", "{title}")
    ],
    "query-expansion-trec-covid": [
        ("Question: \"{title}\" Give me a more comprehensive description based on it.", "{description}"),
        ("Take this query:\n\n{title}\n\nHow can we make it more context-specific?", "{description}"),
        ("Help improve this search request:\n\n{title}\n\nNew request: ", "{description}"),
        ("This is a user query:\n{title}\nExpand it with more details.", "{description}"),
        ("Here is a question\n{title}\nWhat aspects of its topic can be emphasized to improve search?", "{description}"),
        ("Convert this query into a more detailed one: {title}.", "{description}"),
        ("Read this query:\n{title}\nEnhance it with more context that is useful for searching.", "{description}"),
        ("{title}\nAdd some information to the above question.", "{description}"),
        ("You are a query rewriter, you should transform the given query into a more targeted one so that the information need can be better addressed.\n\nQuery:\n{title}", "{description}"),
        ("How to expand this question towards higher retrieval quality?\n{title}\nResult: ", "{description}"),
        ("Take the comprehensive information and create a succinct question:\n{description}", "{title}"),
        ("Generate a concise query from the extensive description:\n{description}", "{title}")
    ],
    "query-expansion-fire": [
        ("Based on the question:\n\n{title}\n\nprovide additional details to make it more informative.", "{description}"),
        ("This is a search request: {title}. Enrich it with relevant context.", "{description}"),
        ("Improve this user query:\n{title}\nEnhance it to yield more accurate search results.", "{description}"),
        ("Expand this query:\n{title}.", "{description}"),
        ("Transform this query into a more precise one: {title}.", "{description}"),
        ("Examine this search query:\n{title}\nAdd relevant information to refine its scope for better results.", "{description}"),
        ("{title}\nInclude additional context to better focus on the preceding question.", "{description}"),
        ("As a query enhancer, your goal is to make this query more effective when searching. Expand the query:\n{title}", "{description}"),
        ("How can we expand the question and enhance the search capabilities?\n{title}", "{description}"),
        ("Query: \"{title}\" Please add more relevant information to it to capture user's information need.", "{description}"),
        ("The verbose version of a query is\n\n{description}\n\nGive me a concise one.", "{title}"),
        ("{description}\nNow simplify it to a query.", "{title}")
    ],
    "query-expansion-query2doc": [
        ("Write a passage that can answer the given query:\n{query}", "{pseudo_doc}"),
        ("What is the expansion of this query:\n\n{query}", "{pseudo_doc}"),
        ("Query:\n\n{query}\n\nRelevant Passage: ", "{pseudo_doc}"),
        ("Here is a query:\n{query}\nGenerate a long-form expansion for it.", "{pseudo_doc}"),
        ("Provide a background document to answer the given question.\n\n{query}\n\nDocument:", "{pseudo_doc}"),
        ("\"{query}\" Expand this query.", "{pseudo_doc}"),
        ("Address the following query with a detailed explanation:\n{query}", "{pseudo_doc}"),
        ("Query: {query} Expansion: ", "{pseudo_doc}"),
        ("Generate a detailed narrative in response to the query:\n{query}", "{pseudo_doc}"),
        ("Please give me a passage to answer the query '{query}'.", "{pseudo_doc}"),
        ("{pseudo_doc}\nWhat question is it raising?", "{query}"),
        ("The expansion is\n{pseudo_doc}\nNow condense it to a query.", "{query}")
    ],
    "query-expansion-trec-cast": [
        ("Here is a query: \"{title}\" Write a description about the user's information need.", "{description}"),
        ("Help add more details for the query:\n{title}", "{description}"),
        ("What is the user's specific search intent when issuing this query:\n{title}", "{description}"),
        ("Query:\n\n{title}\n\nFull description of the information need.", "{description}"),
        ("Interpret the user's query:\n{title}\nWhat is the underlying purpose of this search request?", "{description}"),
        ("Based on the following query, infer what problem the user may meet.\n\n{title}", "{description}"),
        ("What is the user trying to search by this query:\n{title}", "{description}"),
        ("Provide a more precise and comprehensive scope for the user's search:\n{title}", "{description}"),
        ("Elaborate on the user's query:\n{title}", "{description}"),
        ("Unpack the user's search intent in the following query:\n{title}\nWhat specific solution are they seeking?", "{description}"),      
        ("Here is the information need\n{description}\nSimply summarize it to a query.", "{title}"),
        ("The detailed version is\n{description}\nWhat is the corresponding query?", "{title}")   
    ],
    "query-expansion-trec-web": [
        ("Expand the query with more context\n{title}", "{description}"),
        ("Here is a search query:\n\n{title}\n\nWhat does the user trying to find?", "{description}"),
        ("Question:\n{title}\nHow can we expand this query to make it more targeted?", "{description}"),
        ("Dissect the user's query:\n{title}", "{description}"),
        ("Provide additional information to refine the search query:\n{title}", "{description}"),
        ("Interpret the user's intention with this query:\n{title}", "{description}"),
        ("With this initial query, how can we make it more precise and actionable?\n{title}", "{description}"),
        ("Assume a user has this query in mind:\n\n{title}\n\nHow can we make it more informative or detailed?", "{description}"),
        ("Given the query {title}, try to inject more information into it so that the user can fulfill their need.", "{description}"),
        ("{title}\n\nThe above query may be ambiguous. Please write more context for it.", "{description}"),
        ("{description}\nIt describes the information the user want to find. Put it simply as a query.", "{title}"),
        ("Given the detailed description below, generate a query.\n{description}", "{title}")
    ],
    "query-reformulation-codec":[
        ("A question in the area of \"{domain}\" is \"{title}\".\nWe know \"{guidelines}\".\nPlease reform the question.", "{reformulations}"),
        ("Consider the topic of \"{domain}\" with the question \"{title}\". Given the background information \"{guidelines}\", how can we reformulate the question?", "{reformulations}"),
        ("In the field of \"{domain}\", the question \"{title}\" has been raised. Given the guidelines \"{guidelines}\", can you rephrase the question?", "{reformulations}"),
        ("The question \"{title}\" is related to \"{domain}\". With the information \"{guidelines}\", how could we restate the question?", "{reformulations}"),
        ("Given the domain \"{domain}\", the question \"{title}\" arises. Considering the guidelines \"{guidelines}\", please rewrite the question.", "{reformulations}"),
        ("The question is \"{title}\". How can we restructure the question?", "{reformulations}"),
        ("In the context of \"{domain}\", the question \"{title}\" is posed. Given the guidelines \"{guidelines}\", can you rephrase the question differently?", "{reformulations}"),
        ("The question \"{title}\" pertains to the domain \"{domain}\". How can we reword the question in a different way?", "{reformulations}"),
        ("In the \"{domain}\" domain, the question \"{title}\" is asked. Considering the guidelines \"{guidelines}\", reformulate the question.", "{reformulations}"),
        ("The query \"{title}\" is in the \"{domain}\" domain. How can we rephrase the query in another way?", "{reformulations}"),
        ("Given the domain, question, and the guidelines. Reword the question differently.\n\nDomain:\"{domain}\"\n\nQuestion:\"{title}\"\n\nGuidelines:\"{guidelines}\"", "{reformulations}"),
        ("The question is \"{title}\". How can we rewrite the question in a new way?", "{reformulations}")
    ],
    "query-reformulation-qrecc":[
        ("Given a search context \"{context}\". Reformulate the query \"{title}\".", "{reformulations}"),
        ("Context: {context}\n\nQuery: {title}\n\nRewrite the query based on the context in a different way.", "{reformulations}"),
        ("In a conversational question answering system, the question \"{title}\" is asked. The previous context is \"{context}\". How can we rephrase the query?", "{reformulations}"),
        ("In a conversation, the context is \"{context}\", and the currrent question is \"{title}\". How can we reword the inquiry?", "{reformulations}"),
        ("In a dialogue, the context is \"{context}\", and the current question is \"{title}\". How might we rewrite the question?", "{reformulations}"),
        ("During a conversation, the question is \"{title}\". The conversation context is \"{context}\". Rewrite the question.", "{reformulations}"),
        ("Given the dialogue history \"{context}\". The current query is \"{title}\". How can we rewrite the query?", "{reformulations}"),
        ("The question \"{title}\" was proposed after the context \"{context}\". How can we reformulate the question?", "{reformulations}"),
        ("Based on the dialogue context:\n\n{context}\n\nRewrite the following question:\n\n{title}", "{reformulations}"),
        ("Given the question\n\n{title}\n\nPlease rewrite it according to the context\n\n{context}\n\nto make it more clear.", "{reformulations}"),
        ("In a dialogue session, the previous dialogue context is\n\n{context}\n\nNow, the current question is\n\n{title}\n\nHow to reformulate it to make it more clear?", "{reformulations}"),
        ("Here is a dialogue context:\n\n{context}\n\nNow, a new question is proposed:\n\n{title}\n\nCan you reformulate it to be more clear?", "{reformulations}")
    ],
    "query-reformulation-canard":[
        ("Search context: {context}\nHistory: \"{history}\"\nQuery: \"{title}\"\nRewrite the query in a different way.", "{reformulations}"),
        ("In a session \"{history}\", the query \"{title}\" is asked . How can we rephrase the query?", "{reformulations}"),
        ("Someone asked a question \"{title}\" in a conversation \"{history}\". How might we rewrite the question?", "{reformulations}"),
        ("Please rewrite the qustion \"{title}\" based on the context \"{context}\" and search history \"{history}\".", "{reformulations}"),
        ("\"{history}\"\n\nBased on the context above, how can we rephrase the question \"{title}\"?", "{reformulations}"),
        ("In the context of \"{history}\", how can we reformulate the question \"{title}\"?", "{reformulations}"),
        ("Given the search context {context} and history \"{history}\", how might we rewrite the query \"{title}\"?", "{reformulations}"),
        ("In the scenario \"{history}\", how can we rephrase the question \"{title}\"?", "{reformulations}"),
        ("Considering the search context {context} and conversation history \"{history}\", how might we reword the query \"{title}\"?", "{reformulations}"),
        ("With the session context \"{history}\", how can we reformulate the query \"{title}\"?", "{reformulations}"),
        ("Given the previous queries and system responses:\n\n{history}\n\nHow can we reformulate the current query \"{title}\"?", "{reformulations}"),
        ("The search context is \"{history}\", how can we reformulate the new query \"{title}\"?", "{reformulations}")
    ],
    "query-reformulation-cast19": [
        ("Session title: \"{title}\"\nSession description: \"{description}\"\nSession history: \"{history}\"\nQuery: \"{turn_title}\"\nRewrite the query in a different way.", "{reformulations}"),
        ("The current query \"{turn_title}\" is about \"{description}\". The previous search queries include \"{history}\". How can we rephrase the current query?", "{reformulations}"),
        ("Given the session title \"{title}\" and description \"{description}\", and the search context is \"{history}\", how can we rewrite the query \"{turn_title}\"?", "{reformulations}"),
        ("In the session titled \"{title}\" with description \"{description}\", the previous search includes \"{history}\". How can we rephrase the query \"{turn_title}\"?", "{reformulations}"),
        ("Considering the session title \"{title}\" and description \"{description}\", if the search context is \"{history}\", how might we reword the query \"{turn_title}\"?", "{reformulations}"),
        ("Given the session \"{title}\" described as \"{description}\", there are some search contexts include \"{history}\", how can we reformulate the query \"{turn_title}\"?", "{reformulations}"),
        ("In the session \"{title}\" described as \"{description}\", the previous search is \"{history}\". How might we rewrite the query \"{turn_title}\"?", "{reformulations}"),
        ("Considering the session about \"{title}\", the search context is \"{history}\". Can you rephrase the query \"{turn_title}\"?", "{reformulations}"),
        ("Given the session with the topic of \"{title}\", the user's previous interactions with the search engine incldue \"{history}\". Please reformulate the query \"{turn_title}\"", "{reformulations}"),
        ("In the session titled \"{title}\", it is about \"{description}\". The previous search queries are \"{history}\". Reformulate the query \"{turn_title}\"", "{reformulations}"),
        ("Search context:\n\n{history}\n\nReformulate the current query:\n\n{turn_title}", "{reformulations}"),
        ("The search is about \"{title}\". The previous queries include \"{history}\". Now reformulate the query \"{turn_title}\"", "{reformulations}")
    ],
    "query-reformulation-cast2x": [
        ("Session history: \"{history}\"\nQuery: \"{turn_title}\"\nRewrite the query in a different way.", "{reformulations}"),
        ("The previous queries are \"{history}\". The current query is \"{turn_title}\". How can we rephrase it?", "{reformulations}"),
        ("Given the search context as \"{history}\", how can we rewrite the current query \"{turn_title}\"?", "{reformulations}"),
        ("In a session, the previous search queries include \"{history}\". How can we rephrase the query \"{turn_title}\"?", "{reformulations}"),
        ("Considering the search context as \"{history}\", how might we reword the query \"{turn_title}\"?", "{reformulations}"),
        ("Given the search session \"{history}\", how can we reformulate the query \"{turn_title}\"?", "{reformulations}"),
        ("In the session with previous queries of \"{history}\". How might we rewrite the query \"{turn_title}\"?", "{reformulations}"),
        ("Considering the session where the search context is \"{history}\". Can you rephrase the query \"{turn_title}\"?", "{reformulations}"),
        ("Given a session, the user's previous interactions with search engines incldue \"{history}\". Please reformulate the query \"{turn_title}\"", "{reformulations}"),
        ("Reformulate the query \"{turn_title}\" based on the previous queries \"{history}\"", "{reformulations}"),
        ("Search history:\n\n{history}\n\nReformulate the current query: {turn_title}", "{reformulations}"),
        ("Given the following queries\n\n{history}\n\nPlease reformulate the new query: {turn_title}", "{reformulations}")
    ],
    "query-reformulation-gecor": [
        ("\"{title}\"\nRewrite it based on the context:\n\n{context}", "{reformulations}"),
        ("Goal: \"{goal}\"\n\nContext: \"{context}\"\n\nQuery: \"{title}\"\n\nPlease rewrite the query in a different way", "{reformulations}"),
        ("The dialogue context is \"{context}\". The user input is \"{title}\". How can we rephrase the user input?", "{reformulations}"),
        ("Reformulate the user input \"{title}\" given the goal \"{goal}\" and the context \"{context}\"", "{reformulations}"),
        ("In a dialogue with the goal \"{goal}\" and context \"{context}\", how might we rephrase the user input \"{title}\"?", "{reformulations}"),
        ("Considering the dialogue goal \"{goal}\" and context \"{context}\", how can we reformulate the user input \"{title}\"?", "{reformulations}"),
        ("Given the dialogue context \"{context}\", how can we rewrite the user input \"{title}\"?", "{reformulations}"),
        ("Given the dialogue's goal \"{goal}\" and context \"{context}\", how can we rephrase the user's input \"{title}\"?", "{reformulations}"),
        ("In a conversation with the aim of \"{goal}\" and context of \"{context}\", how might we reformulate the user's query \"{title}\"?", "{reformulations}"),
        ("Considering the goal \"{goal}\" and context \"{context}\" of the dialogue, how can we rewrite the user's query \"{title}\"?", "{reformulations}"),
        ("Given the dialogue context as \"{context}\", the current user input is \"{title}\". Please help reformulate it to be more clear.", "{reformulations}"),
        ("For a dialogue context \"{context}\", how can we rewrite the user's current input \"{title}\"?", "{reformulations}")
    ],
    "query-clarification-mimics": [
        ("Query: \"{query}\". Clarify the query.", "{clarification}"),
        ("Query: {query}\n\nClarification: ", "{clarification}"),
        ("Make some clarifications for the query \"{query}\"", "{clarification}"),
        ("Query: \"{query}\"\nWhat are the possible clarifications?", "{clarification}"),
        ("User input: \"{query}\". Please ask a clarification question.", "{clarification}"),
        ("{query}\nCan you clarify the above query?", "{clarification}"),
        ("Considering the query \"{query}\", what clarification options would you suggest?", "{clarification}"),
        ("{query}\n\nWhat clarification options can be suggested?", "{clarification}"),
        ("Identify some clarification queries for the query \"{query}\"", "{clarification}"),
        ("If the query is \"{query}\", can you ask some clarification questions?", "{clarification}"),
        ("Clarify the following query: \"{query}\" Clarification: ", "{clarification}"),
        ("Provide some clarifications for the given query \"{query}\"", "{clarification}")
    ],
    "query-clarification-mimics-duo": [
        ("Query:\n\n{query}\n\nClarify the query to refine the search.", "{clarification}"),
        ("Query: {query}\nClarification: ", "{clarification}"),
        ("Make some clarifications for the query \"{query}\"", "{clarification}"),
        ("Query: \"{query}\"\nWhat are the possible clarifications?", "{clarification}"),
        ("User input: \"{query}\". Please provide me with some clarification questions.", "{clarification}"),
        ("{query}\n\nCan you clarify this query?", "{clarification}"),
        ("Considering the query \"{query}\", what clarification questions would you ask?", "{clarification}"),
        ("\"{query}\"\n\nWhat clarification question can be asked?", "{clarification}"),
        ("Identify some possible clarifications for the query \"{query}\"", "{clarification}"),
        ("If the query is \"{query}\", how would you clarifiy it?", "{clarification}"),
        ("If a user input a query \"{query}\", how to clarify it and understand her/his search intent?", "{clarification}"),
        ("When the \"{query}\" is given, what are possible clarifications?", "{clarification}")
    ],
    "query-clarification-clariq-fkw": [
        ("Query: {title} Clarification: ", "{clarification}"),
        ("Query: \"{title}\"\nPlease try to ask me a clarification question.", "{clarification}"),
        ("The query is \"{title}\". Ask a clarification question for it.", "{clarification}"),
        ("If you are asked with the query \"{title}\", how do you need to clarify?", "{clarification}"),
        ("Query: {title}\n\nIf you want to understand the previous query, what clarification questions will you ask?", "{clarification}"),
        ("If I want to understand the user query \"{title}\", what clarification questions do I need?", "{clarification}"),
        ("Can you ask a clarification question about \"{title}\"?", "{clarification}"),
        ("\"{title}\" - how to ask a clarification question?", "{clarification}"),
        ("I have a query \"{title}\". If you are a search engine, how will you clarify this query?", "{clarification}"),
        ("The query is \"{title}\". If you are required to provide me with some relevant documents, what questions will you ask?", "{clarification}"),
        ("Ask a clarification question for the query \"{title}\"", "{clarification}"),
        ("Given a query \"{title}\", provide me with a clarification question.", "{clarification}"),
    ],
    "query-clarification-raocq": [
        ("Query: {title}. {description}, ask a clarification querstion.", "{clarification}"),
        ("Here are some descriptions \"{description}\" about \"{title}\", if you want to answer the question, what do you need to clarify?", "{clarification}"),
        ("The problem is {title}. The descrption is {description}. Can you ask a clarification question to help understand the problem?", "{clarification}"),
        ("Given a problem {title} and its description {description}. You need to ask a relevant clarification question to help deal with the problem.", "{clarification}"),
        ("Title:\n\n{title}\n\nDescription:\n\n{description}\n\nAsk a clarification question for the problem.", "{clarification}"),
        ("If you want to solve a problem \"{description}\" about {title}, what do you need to clarify?", "{clarification}"),
        ("I'm faced with a problem {description} about {title}. You need to provide me with some suggestions. What do you need to know?", "{clarification}"),
        ("{title}. {description} Can you help me to solve it?", "{clarification}"),
        ("I meet a problem about {title}. {description}. How can I solve it?", "{clarification}"),
        ("Can you help me solve this problem?\n\n{title}\n\nDescription: {description}", "{clarification}"),
        ("I have a problem about {title}. More detailed description is: {description}. You need to help me with my problem, and what information do you need to know?", "{clarification}"),
        ("Question: {title}\n\nDescription: {description}\n\nPlease help me to solve it. Is there any question you want to know?", "{clarification}")
    ],
    "query-subtopic-generation-trec-web": [
        ("Query: {title}\nGenerate some subtopics.", "{subtopic_title}"),
        ("Given the query \"{title}\" and its description \"{description}\", please generate its subtopics. The subtopics should be relevant to the query but describe different aspects.", "{subtopic_title}"),
        ("The query is \"{title}\". Generate its subtopics: ", "{subtopic_title}"),
        ("Query\n\n{title}\n\nIts subtopics can be: ", "{subtopic_title}"),
        ("Here is a query \"{title}\". Its description is \"{description}\". Please provide some subtopics about the query.", "{subtopic_title}"),
        ("Here are some descriptions about the query \"{title}\": {description} Generate the query's subtopics.", "{subtopic_title}"),
        ("Please generate some subtopics about the query: {title}", "{subtopic_title}"),
        ("Can you provide some subtopics in terms of the query {title}?", "{subtopic_title}"),
        ("If the query is {title}, can you porvide some subtopics?", "{subtopic_title}"),
        ("I have a query {title} Please provide me with some subtopics.", "{subtopic_title}"),
        ("Generate some possible subtopics for the query {title}", "{subtopic_title}"),
        ("Please provide me with some possible subtopics about {title}", "{subtopic_title}")
    ],
    "query-matching-msrp": [
        ("Here are two sentences:\n{sentence1}\n{sentence2}\nDo they have the same meaning?\n- yes\n- no", "{answer}"),
        ("Here are two sentences:\n\n{sentence1}\n\n{sentence2}\nAre the two sentences saying the same thing?", "{answer}"),
        ("{sentence1}\n\n{sentence2}\n\nDo the above sentences mean the same thing?", "{answer}"),
        ("{sentence1}\n\n{sentence2}\n\nPlease tell me if the sentences above mean the same.\n\nOptions:\n-yes \n-no", "{answer}"),
        ("{sentence1}\n{sentence2}\nAre these sentences conveying the same meaning?", "{answer}"),
        ("{sentence1}\n{sentence2}\nIf the first sentence is true, is the second one also true?", "{answer}"),
        ("{sentence1}\n{sentence2}\nAre these two sentences paraphrases of each other? Options: - yes - no", "{answer}"),
        ("Do the following two sentences have the same meaning?\n{sentence1}\n{sentence2}", "{answer}"),
        ("Do these two sentences mean the same thing?\n{sentence1}\n{sentence2}", "{answer}"),
        ("Do these sentences have the same meaning?\n{sentence1}\n{sentence2}", "{answer}"),
        ("Judge whether the following two sentences have the same meaning:\n\n1. {sentence1}\n\n2. {sentence2}", "{answer}"),
        ("Please check whether the two sentences have the same meaning.\n\n{sentence1}\n\n{sentence2}", "{answer}")
    ],
    "qury-suggestion-aol": [
        ("Search context:\n{context}\nInfer the next query: ", "{target_query}"),
        ("Given the search context as follows:\n{context}\nPlease suggest the next query.", "{target_query}"),
        ("The search context is presented below:\n{context}\nCan you predict the next query?", "{target_query}"),
        ("Generate the next query based on the prevous queries \"{history_queries}\".", "{target_query}"),
        ("In a search session, the previous queries include \"{history_queries}\", and their corresponding clicked documents are {history_docs}. Generate the next query.", "{target_query}"),
        ("{context}\n\nAccording to the above search session information, predict the next query: ", "{target_query}"),
        ("The user's search session is as follows:\n{context}\nWhat is the possible next query?", "{target_query}"),
        ("Given a search session as:\n{context}\nYou need to suggest the next query.", "{target_query}"),
        ("My previous search context is:\n{context}\nPlease suggest me the next query.", "{target_query}"),
        ("Predict the next query based on the previous queries: {history_queries}", "{target_query}"),
        ("Infer the next query based on the previous ones: {history_queries}", "{target_query}"),
        ("Here are some queries: \"{history_queries}\" Can you infer the next one?", "{target_query}")
    ],
    "query-intent-classification-orcas-i": [
        ("Query: \"{title}\"\nWhat is the type of the query?\n\nOptions:\n- factual\n- abstain\n- instrumental\n- transactional\n- navigational", "{query_type}"),
        ("What is the intent type of the query \"{title}\"? Please select from {factual, abstain, instrumental, transactional, navigational}", "{query_type}"),
        ("\"{title}\"\nWhat type of query is it? OPTIONS:\nA. factual\nB. abstain\nC. instrumental\nD. transactional\nE. navigational", "{query_type}"),
        ("\"{title}\"\nWhat is the intent type of the query? Select one from the following options:\n(A) factual\n(B) abstain\n(C) instrumental\n(D) transactional\n(E) navigational", "{query_type}"),
        ("Given the question \"{title}\", its intent label (factual, abstain, instrumental, transactional, or navigational) is: ", "{query_type}"),
        ("A user asked \"{title}\". What may be the type of the user's intent?\n\nOptions:\n- factual\n- abstain\n- instrumental\n- transactional\n- navigational", "{query_type}"),
        ("\"{title}\". Can you identify the query type? Options:\n[A] factual\n[B] abstain\n[C] instrumental\n[D] transactional\n[E] navigational", "{query_type}"),
        ("Considering the query \"{title}\", what might be the type of the user's intent? Options:\n- factual\n- abstain\n- instrumental\n- transactional\n- navigational", "{query_type}"),
        ("\"{title}\". What could be the possible type of intent of this query? Options:\n1. factual\n2. abstain\n3. instrumental\n4. transactional\n5. navigational", "{query_type}"),
        ("Identify the type of the query \"{title}\".\n\nOptions:\n- factual\n- abstain\n- instrumental\n- transactional\n- navigational", "{query_type}"),
        ("When looking at the query \"{title}\", what could be the user's intention? Options:\n- informative\n- undecided\n- functional\n- transactional\n- directional", "{query_type}"),
        ("What is the purpose of the query \"{title}\"? Please select one of the following:\nI. informative\nII. undecided\nIII. functional\nIV. transactional\nV. directional", "{query_type}"),
    ],
    "query-intent-classification-mantis": [
        ("In a session about \"{title}\". User asked \"{turn_title}\". What is the type of the question? Options: {original question, further details, follow up question, information request, potential answer, positive feedback, negative feedback, greetings / gratitude, other}", "{query_type}"),
        ("Given the session \"{title}\" and the question \"{turn_title}\", what is the query type? Options: original question, further details, follow up question, information request, potential answer, positive feedback, negative feedback, greetings / gratitude, other", "{query_type}"),
        ("\"{turn_title}\" was asked in the session about \"{title}\". What is the query's type? You can select one or several types from the options {original question, further details, follow up question, information request, potential answer, positive feedback, negative feedback, greetings / gratitude, other}", "{query_type}"),
        ("In the context of \"{title}\", the user asked \"{turn_title}\". What is the query type? Select suitable labels from {original question, further details, follow up question, information request, potential answer, positive feedback, negative feedback, greetings / gratitude, other}", "{query_type}"),
        ("The user asked \"{turn_title}\" in a session about \"{title}\". What is the type of user intent? Options:\nA. further details\nB. follow up question\nC. information request\nD. potential answer\nE. positive feedback\nF. negative feedback\nG. greetings / gratitude\nH. other\nI. original question", "{query_type}"),
        ("\"{turn_title}\". In the context of \"{context}\", what is the query type? Options:\nA. further details\nB. follow up question\nC. information request\nD. potential answer\nE. positive feedback\nF. negative feedback\nG. greetings / gratitude\nH. other\nI. original question", "{query_type}"),
        ("Considering the session \"{title}\" and the context \"{context}\", the user asked \"{turn_title}\". Select the question type from {further details, follow up question, original question, information request, potential answer, positive feedback, negative feedback, greetings / gratitude, other}", "{query_type}"),
        ("\"{turn_title}\" was asked during the \"{title}\" session. The session context is \"{context}\". What is the query type? Options: A. further details B. follow up question C. information request D. potential answer E. positive feedback F. original question G. negative feedback H. greetings / gratitude I. other", "{query_type}"),
        ("Identify the intent of the question \"{turn_title}\" in the session \"{title}\" with the context of \"{context}\". Options:\n- further details\n- follow up question\n- information request\n- potential answer\n- original question\n- positive feedback\n- negative feedback\n- greetings / gratitude\n- other", "{query_type}"),
        ("\"{turn_title}\".\n In the session about \"{title}\", given the context as \"{context}\", what is the intent type of this question?\nOptions:\n\n- further details\n- follow up question\n- information request\n- potential answer\n- original question\n- positive feedback\n- negative feedback\n- greetings / gratitude\n- other", "{query_type}"),
        ("Within the session about \"{title}\", considering the context as \"{context}\", what is the intent type of this question \"{turn_title}\"?\nOptions:\n\n1. elaboration\n2. follow-up\n3. information request\n4. potential answer\n5. initial query\n6. positive feedback\n7. negative feedback\n8. greetings / gratitude\n9. other", "{query_type}"),
        ("Determine the intent of the question \"{turn_title}\" in the session \"{title}\". Options:\n- elaboration\n- follow-up\n- information request\n- potential answer\n- initial query\n- positive feedback\n- negative feedback\n- greetings / gratitude\n- other", "{query_type}"),
    ],
    "query-intent-classification-trec-web": [
        ("Query: \"{title}\"\nQuery description: \"{description}\"\nWhat is the type of the query (faceted or ambiguous)?", "{query_type}"),
        ("Given the query \"{title}\" and its description \"{descrisption}\", what is the query type? Options: - faceted - ambiguous", "{query_type}"),
        ("The query is: \"{title}\", its description is \"{description}\". Is it a faceted query or an ambiguous query?", "{query_type}"),
        ("In terms of the query {title} and its description \"{description}\", what is the type of the query? Options:\n- faceted\n- ambiguous", "{query_type}"),
        ("The user queried \"{title}\" with description \"{description}\". What is the type of the query? Options: (A) faceted (B) ambiguous", "{query_type}"),
        ("Under a query \"{title}\" with description \"{description}\", a potential subtopic is \"{subtopic}\". What is the type of the subtopic (informational or navigational)?", "{subtopic_type}"),
        ("Considering the query \"{title}\", Can you infer whether it is an ambiguous query or a faceted query?", "{query_type}"),
        ("The query is {title}. Please identify its type (faceted or ambiguous): ", "{query_type}"),
        ("Identify the type of the query \"{title}\". Options: - faceted - ambiguous", "{query_type}"),
        ("\"{title}\". what is the type of this query? Options:\n\n- faceted\n- ambiguous", "{query_type}"),
        ("Is the query \"{title}\" a faceted query or an ambiguous query?", "{query_type}"),
        ("Please label the query with the type (faceted or ambiguous). \"{title}\"", "{query_type}")
    ],
    "fact-verification-fever": [
        ("Claim: \"{claim}\"\nEvidence: \"{evidences}\"\nPlease label whether the claim is supported or refuted by the evidence. Options: - support - refute", "{claim_label}"),
        ("Given the claim \"{claim}\" and the evidence \"{evidences}\", please provide a label to indicate if the evidence supports or refutes the claim.", "{claim_label}"),
        ("Please provide a label (support or refute) for the claim \"{claim}\" based on the evidence \"{evidences}\".", "{claim_label}"),
        ("\"{claim}\"\nBased on the evidence \"{evidences}\", is the claim supported or refuted by the evidence?", "{claim_label}"),
        ("Considering the claim \"{claim}\" and the evidence \"{evidences}\", does the evidences support or refute the claim?", "{claim_label}"),
        ("\"{claim}\"\nGiven the evidence \"{evidences}\", does it support or refute the claim?", "{claim_label}"),
        ("Please assign a label to the claim \"{claim}\" considering the evidence \"{evidences}\". Options: - support - refute. Choose the label that best reflects the relationship between the claim and the evidence.", "{claim_label}"),
        ("Claim: {claim}\n\nEvidence: {evidences}\n\nCheck whether the evidence supports or refutes the claim.", "{claim_label}"),
        ("Label the relationship between the claim \"{claim}\" and the evidence \"{evidences}\". You can select a label from {support, refute}.", "{claim_label}"),
        ("\"{claim}\"\nBased on \"{evidences}\", which label {support or refute} can reflect their relationship?", "{claim_label}"),
        ("Given the evidence \"{evidences}\", determine the appropriate label to describe its relationship with the claim \"{claim}\". The options are 'support' or 'refute'.", "{claim_label}"),
        ("Does the evidence '{evidences}' support or refute the claim \"{claim}\"?", "{claim_label}")
    ],
    "fact-verification-climate-fever": [
        ("Check the following claim \"{claim}\" and the corresponding evidences \"{evidences}\". Determine if the evidences 'support' or 'refute' the claim. If the claim is disputed, respond with 'disputed'. If the information is not enough, respond with 'not enough information'.", "{claim_label}"),
        ("Claim: \"{claim}\"\n\nEvidence: \"{evidences}\"\n\nPlease label whether the evidences 'support' or 'refute' the claim. If the information is not enough, respond with 'not enough information'. If the claim is disputed, indicate this by responding with 'disputed'.", "{claim_label}"),
        ("Based on the given claim \"{claim}\" and the provided evidence \"{evidences}\", assign a label from the following options: 'support', 'refute', 'disputed', or 'not enough information'. This label should reflect whether the evidence supports or refutes the claim, if there is insufficient information to reach a conclusion, or if the claim itself is a matter of dispute.", "{claim_label}"),
        ("Can you label the claim \"{claim}\" based on the evidence \"{evidences}\"? Options:\n- support-\ndisputed\n- refute\n- not enough information\nChoose a label that best describes the relationship between the evidence and the claim: whether the evidence supports or refutes the claim, if the claim is disputed, or if there is not enough information for a definitive decision.", "{claim_label}"),
        ("Examine the relationship between the claim \"{claim}\" and the provided evidence \"{evidences}\". Select a label that best represents this relationship. Your options are: (A) support (B) refute (C) not enough information (D) disputed", "{claim_label}"),
        ("Does the evidence \"{evidences}\" support or refute the claim \"{claim}\"? If the provided information is not enough to make a decision, respond with 'not enough information'. If the claim itself is disputed, respond with 'disputed'. Options: A. support B. refute C. not enough information D. disputed", "{claim_label}"),
        ("Does the evidence \"{evidences}\" support or refute the claim \"{claim}\"? Is the claim disputed, or is there not enough information available to make a decision?", "{claim_label}"),
        ("\"{claim}\"\n\nGiven the evidence \"{evidences}\", what is the appropriate label for the evidence? Options:\nA. support\nB. disputed\nC. refute\nD. not enough information\nSelect the option that best reflects whether the evidence supports or refutes the claim, whether there is sufficient information to make a decision, or if the claim itself is disputed.", "{claim_label}"),
        ("Examine the relationship between the claim \"{claim}\" and the evidence \"{evidences}\". Choose the option that best describes this relationship. Options:\n\n- support\n- refute\n- not enough information\n- disputed", "{claim_label}"),
        ("The claim is \"{claim}\". Based on the given evidence \"{evidences}\", assess whether it supports or refutes the claim. If the information is inadequate for a conclusive decision, select 'not enough information', and if the claim is inherently disputed, choose 'disputed'. Options:\n[A] support\n[B] refute\n[C] not enough information\n[D] disputed", "{claim_label}"),
        ("Please label the claim \"{claim}\" based on the provided evidence \"{evidences}\". Options:\n(I) support\n(II) refute\n(III) disputed\n(IV) not enough information\nChoose the label that accurately indicates if the evidence supports or refutes the claim, if there is adequate information to make a decision, or if the claim itself is a matter of dispute.", "{claim_label}"),
        ("I have a claim about the climate: \"{claim}\".\n\nHere are some evidences:\n\n{evidences}\n\nPlease label it. Options:\n1. support\n2. refute\n3. disputed\n4. not enough information\nSelect the label that accurately indicates whether the evidence supports or refutes the claim, whether there is sufficient information for a decision, or if the claim itself is a matter of dispute.", "{claim_label}")
    ],
    "fact-verification-scifact": [
        ("Claim: \"{claim}\"\n\nEvidence: \"{evidence}\"\n\nPlease label whether the evidence support or refute the claim.", "{evidence_label}"),
        ("Given the claim \"{claim}\" and the evidence \"{evidence}\", does the evidence support the claim? Please provide a label (support or refute).", "{evidence_label}"),
        ("Judge the relationship between the evidence \"{evidence}\" and the claim \"{claim}\" Options: - support - refute", "{evidence_label}"),
        ("Based on the evidence \"{evidence}\", does it support or refute the claim \"{claim}\"? Options: A. support B. refute", "{evidence_label}"),
        ("Claim: {claim}\nConsidering the evidence \"{evidence}\", does the evidence support the claim? Options: (A) support (B) refute", "{evidence_label}"),
        ("Please label whether the claim \"{claim}\" is supported or refuted by the evidence \"{evidence}\"\n\n(A) support\n(B) refute", "{evidence_label}"),
        ("Here's a claim \"{claim}\" and some evidences \"{evidence}\". Does the evidence support or refute the claim?","{evidence_label}"),
        ("According to the evidence \"{evidence}\", does it support or refute the claim \"{claim}\"?", "{evidence_label}"),
        ("Label whether the claim \"{claim}\" is supported or refuted by the evidence \"{evidence}\". Options:\n\nA. support\nB. refute","{evidence_label}"),
        ("If \"{evidence}\" is true, does it support or refute the claim \"{claim}\"?", "{evidence_label}"),
        ("{claim}\n\nGiven the evidence \"{evidence}\", does it support or refute the previous claim? Options:\n\nA. support\nB. refute", "{evidence_label}"),
        ("{evidence}\n\nDoes the evidence support or refute the claim \"{claim}\"? Options:\n\nA. support\nB. refute", "{evidence_label}")
    ],
    "summarization-xsum": [
        ("Summarize:\n\n{article}\n\nSummary:", "{summary}"),
        ("Summarize this article:\n\n{article}", "{summary}"),
        ("Summarize this article in your own words.\n\n{article}", "{summary}"),
        ("{article}\nWhat is a summary of this text?", "{summary}"),
        ("{article}\nWhat is this article about?", "{summary}"),
        ("{article}\n\nThis article is about:", "{summary}"),
        ("Article: {article}\n\nA summary of the above article is?", "{summary}"),
        ("Article: {article}\n\nSummarize the main points of that article.", "{summary}"),
        ("Summarize this article in one sentence.\n\n{article}", "{summary}"),
        ("{article}\n\nSummarize the article, please.", "{summary}"),
        ("Write an article based on this summary:\n\n{summary}", "{article}"),
        ("{summary}\n\nWrite an article based on the above summary.", "{article}"),
    ],
    "summarization-cnn-dm": [
        ("Write a summary for this article:\n\n{article}\n\nSummary:", "{summary}"),
        ("{article}\n\nSummarize it", "{summary}"),
        ("{article}\n\nGive me a summary.", "{summary}"),
        ("{article}\n\nWhat are the important points of the article?", "{summary}"),
        ("Generate the summary of:\n\n{article}\n\nSummary: ", "{summary}"),
        ("Here is an article:\n{article}\nWrite a short summary", "{summary}"),
        ("Article:\n{article}\nWhat are the main points in that article?", "{summary}"),
        ("{article}\n\nBriefly summarize that article.", "{summary}"),
        ("{article}\n\nWrite highlights for this article.", "{summary}"),
        ("{article}\n\nWhat are highlight points for this article?", "{summary}"),
        ("Craft an article using the provided summary:\n\n{summary}", "{article}"),
        ("Given the summary below, extend the content to form an article:\n\n{summary}", "{article}"),
    ],
    "summarization-wikisum": [
        ("Generate a short summary for this article:\n\n{article}", "{summary}"),
        ("Write a short summary for this text: {article}", "{summary}"),
        ("Briefly summarize this wiki page: {article}", "{summary}"),
        ("What is a shorter version of this:\n\n{article}", "{summary}"),
        ("{article}\n\nWrite a brief summary in few sentences.", "{summary}"),
        ("{article}\n\nWhat is a very short summary of the above text?", "{summary}"),
        ("{article}\n\nSummarize the aforementioned text.", "{summary}"),
        ("{article}\n\nCan you generate a short summary of the above paragraph?", "{summary}"),
        ("Please summarize the wiki page:\n{article}", "{summary}"),
        ("{article}\n\nWhat are the most important parts of this text?", "{summary}"),
        ("Please expand the following text into a more detailed wiki page:\n{summary}", "{article}"),
        ("Can you write a text in Wikipedia style based an the summary below?\n\n{summary}", "{article}")
    ],
    "summarization-multi-news": [
        ("Summarize these articles:\n\n{article}", "{summary}"),
        ("Write a summary based on these articles:\n\n{article}", "{summary}"),
        ("Articles:\n\n{article}\nWhat is a summary?", "{summary}"),
        ("{article}\n\nWhat is a one-paragraph summary of the above articles?", "{summary}"),
        ("Here are some news article: {article}\n\nA summary of these is? Summary: ", "{summary}"),
        ("News articles:\n\n{article}\n\nWhat is a shorter version of the above articles?", "{summary}"),
        ("{article}\n\nWrite a summary.", "{summary}"),
        ("Articles:\n\n{article}\n\nSummary: ", "{summary}"),
        ("Given these articles:\n\n{article}\n\nCan you provide a brief summary?", "{summary}"),
        ("These are the articles:\n\n{article}\n\nWhat would be a concise summary?", "{summary}"),
        ("Please help me summarize these news articles\n\n{article}", "{summary}"),
        ("{article}\n\nWhat is a summary of the above articles?", "{summary}")
    ],
    "reading-comprehension-squad": [
        ("{title}:\n\n{context}\n\nPlease answer a question about this article. If the question is unanswerable, say \"unanswerable\". {question}", "{answer}"),
        ("Read this and answer the question. If the question is unanswerable, say \"unanswerable\".\n\n{context}\n\n{question}", "{answer}"),
        ("What is a question about this article? If the question is unanswerable, say \"unanswerable\".\n\n{context}\n\n{question}", "{answer}"),
        ("{context}\n{question} (If the question is unanswerable, say \"unanswerable\")", "{answer}"),
        ("{context}\nTry to answer this question if possible (otherwise reply \"unanswerable\"): {question}", "{answer}"),
        ("{context}\nIf it is possible to answer this question, answer it for me (else, reply \"unanswerable\"): {question}", "{answer}"),
        ("{context}\n\nAnswer this question, if possible (if impossible, reply \"unanswerable\"): {question}", "{answer}"),
        ("Read this: {context}\n\n{question}\nWhat is the answer? (If it cannot be answered, return \"unanswerable\")", "{answer}"),
        ("Read this: {context}\nNow answer this question, if there is an answer (If it cannot be answered, return \"unanswerable\"): {question}", "{answer}"),
        ("{context}\nIs there an answer to this question (If it cannot be answered, say \"unanswerable\"): {question}", "{answer}"),
        ("{context}\n\nPlease answer the question \"{question}\". If it cannot be answered, return unanswerable.", "{answer}"),
        ("Article: {context}\n\nQuestion: {question}\n\nGive me the answer (if the question cannot be answered based on the article, just return unanswerable)", "{answer}")
    ],
    "reading-comprehension-hotpot-qa": [
        ("Given the question: {question}, refer to the facts and generate your answer\n{supporting_facts}", "{answer}"),
        ("Considering the question: {question}, consult the facts below and answer it\n{supporting_facts}", "{answer}"),
        ("There are some facts\n{supporting_facts}\n\nBased on them, answer the question\n{question}", "{answer}"),
        ("Using the following details: {supporting_facts}\nExamine the question: {question}\nGenerate your response based on the facts.", "{answer}"),
        ("Refer to the supporting facts: {supporting_facts}\nGiven the question: {question}, provide your answer.", "{answer}"),
        ("Question: {question}\nConsult the provided facts and generate your answer\n{supporting_facts}", "{answer}"),
        ("Given the question: {question}\nGenerate your answer based on the following facts\n{supporting_facts}", "{answer}"),
        ("Review the question: {question}\nAnswer it considering the provided facts\n{supporting_facts}", "{answer}"),
        ("Evaluate the question: {question}\nConsult the provided facts\n{supporting_facts}\nAnswer the question.", "{answer}"),
        ("Review the supporting facts: {supporting_facts}\nExamine the question: {question}\nGenerate your response accordingly.", "{answer}"),
        ("Based on the following facts\n\n{supporting_facts}, answer the question: {question}", "{answer}"),
        ("{supporting_facts}\n\nThe question is {question}. Please answer it.", "{answer}"),
    ],
    "reading-comprehension-ms-marco": [
        ("Given a document\n{context}\n\nNow answer the question: {question}", "{answer}"),
        ("Answer the question: {question}\n\nBased on an article\n\n{context}", "{answer}"),
        ("Question: {question}\nPlease read this article: {context}, then answer the question.", "{answer}"),
        ("Read the passage: {context}\nThen answer the question: {question}", "{answer}"),
        ("Question: {question}\nRead this article: {context}\nAnswer the question.", "{answer}"),
        ("Given this question: {question}\n\nBased on these facts: {supporting_facts}\n\nAnd a related passage: {context}\n\nGenerate your answer.", "{answer}"),
        ("Consider the passage: {context}\nThen answer the question {question}", "{answer}"),
        ("Keep some facts in mind: {supporting_facts}\n\nThen answer the question: {question}\n\nBased on the context: {context}", "{answer}"),
        ("Question: {question}\n\nContext: {context}\n\nPlease answer the question.", "{answer}"),
        ("There is a passage and some facts related to a question\n\n{context}\n\n{supporting_facts}\n\nNow answer it: {question}", "{answer}"),
        ("Read the following context and answer the question: {question}\n\n{context}", "{answer}"),
        ("{context}\n\n{question}\n\nAnswer the previous question based on the given material.", "{answer}"),
    ],
    "reading-comprehension-trivia-qa": [
        ("Answer the question: {question}", "{answer}"),
        ("What is the answer is the question: {question}", "{answer}"),
        ("Write the answer of: {question}", "{answer}"),
        ("Question: \"{question}\", please answer.", "{answer}"),
        ("{question}", "{answer}"),
        ("{context}\n\nConsulting this, give your answer to: {question}", "{answer}"),
        ("{question}\n\nAnswer this question referring to: {context}", "{answer}"),
        ("Given the passage: {context}\nNow, provide the answer to the question: {question}", "{answer}"),
        ("Consider the context: {context}\nNow, write the answer to the question: {question}", "{answer}"),
        ("{context}\nAnswer the following question: {question}", "{answer}"),
        ("Given the question: {question}\nPlease infer the answer.", "{answer}"),
        ("{context}\n\n{question}\nWhat is the answer?", "{answer}"),
    ],
    "reading-comprehension-bool-q": [
        ("{context}\nIs it true that {question}? Please answer in \"True\" or \"False\"", "{answer}"),
        ("{context}\nFigure out if it is real or not: {question}\nOptions: \"True\" or \"False\"", "{answer}"),
        ("Given an article: {context}\nDecide the genuineness: {question}", "{answer}"),
        ("{context}\nIs the statement correct? (True/False)\n{question}", "{answer}"),
        ("{question}\nIs the question supported by the text? {context}", "{answer}"),
        ("{question}\nNow read the passage and examine if the answer is \"True\": {context}", "{answer}"),
        ("{context}\nBased on this article, is it true that {question}", "{answer}"),
        ("{context}\nCan we confirm the truthfulness of {question}? Please answer in \"True\" or \"False\"", "{answer}"),
        ("{context}\nDetermine whether it is true or not: {question}", "{answer}"),
        ("{question}\nIs it true given this: {context}", "{answer}"),
        ("Is it true that {question} based on the following text?\n\n{context}", "{answer}"),
        ("{context}\n\n{question}? (True or False)", "{answer}"),
    ],
    "reading-comprehension-webglm-qa": [
        ("Answer the question: {question}\nGiven references: {references}", "{answer}"),
        ("Question: {question}\nReferences: {references}\nNow answer the question based on the references.", "{answer}"),
        ("{references}\nNow{question}", "{answer}"),
        ("{references}\nAfter reading the above, answer this question: {question}", "{answer}"),
        ("{references}\nThen generate your answer to this question: {question}", "{answer}"),
        ("Provide the answer for: {question}\nSupported by: {references}", "{answer}"),
        ("Given the references below, answer the question: {question}\nReferences: {references}", "{answer}"),
        ("Explore the references and{question}\nReferences: {references}", "{answer}"),
        ("References available: {references}\nAfter reviewing the references, response to: {question}", "{answer}"),
        ("{references}\n\nRead these passages and answer the question: {question}", "{answer}"),
        ("{references}\n\n{question}\n\nAnswer the question.", "{answer}"),
        ("According to the references: {references}\n\nAnswer the question: {question}", "{answer}"),
    ],
    "conversational-qa-coqa": [
        ("{context}\n{history}\nAnswer the question: {questions}", "{answers}"),
        ("Answer the questions at the end based on:\n{context}\n\n{questions}", "{answers}"),
        ("Given the passage\n{context}\nand previous dialogue history\n{history}\nAnswer the questions: {questions}", "{answers}"),
        ("{context}\n\nWhat are the answers to these questions: {questions}", "{answers}"),
        ("{context}\n\n{questions}\n\nGive me a numbered list of answers.", "{answers}"),
        ("Read the article below, then answer the questions\n\n{context}\n\n{questions}", "{answers}"),
        ("Respond to the following questions in light of the provided context:\n{context}\nQuestions: {questions}", "{answers}"),
        ("In the context provided, answer the following questions:\n{context}\nQuestions: {questions}", "{answers}"),
        ("{context}\n\nAnswer this series of questions:\n\n{questions}", "{answers}"),
        ("After reading the article and previous dialogue history, answer the accompanying question:\nContext: {context}\nHistory: {history}\nQuestions: {questions}", "{answers}"),
        ("Make use of the article to answer the questions.\n\n{context}\n\n{questions}", "{answers}"),
        ("{context}\n\nBased on the article, answer the following list of questions.\n\n{questions}", "{answers}"),
    ],
    "conversational-qa-quac": [
        ("Extract the answer of {question} from the background\n\n{background}\n\nand context\n\n{context}\n\nwith previous dialogue history\n\n{history}", "{answers}"),
        ("{background}\n\n{context}\n\nTake a quote from it as the answer to the question: {question}", "{answers}"),
        ("Which excerpt can be the answer to the question?\nBackground: {background}\nContext: {context}\nQuestion: {question}", "{answers}"),
        ("{background}\n\n{context}\n\nAnswer this: {question}, by extracting a quote from the background above.", "{answers}"),
        ("Retrieve the response to {question} from the background and context provided\nBackground: {background}\nContext: {context}", "{answers}"),
        ("Select a relevant quote from the following background as the answer to: {question}\nBackground: {background}\nContext: {context}", "{answers}"),
        ("Consider the following background and previous dialogue history, then derive an answer to: {question}\nBackground: {background}\nContext: {context}\nHistory: {history}", "{answers}"),
        ("Background: {background}\nContext: {context}\nWithin the context provided, choose the quote that answers the following question: {question}", "{answers}"),
        ("{background}\n{context}\nDelve into the background information about the previous dialogue history \"{history}\", then generate the response to: {question}", "{answers}"),
        ("Identify the excerpt as the answer to the question at the end:\n{background}\n{context}\nQuestion: {question}", "{answers}"),
        ("Background: {background}\nContext: {context}\nQuestion: {question}", "{answers}"),
        ("{background}\n\n{context}\n\nHere is a question: {question}. Please answer it.", "{answers}"),
    ],
    "general-retrieval-ms-marco": [
        ("Assess the relevance between the provided document:\n{document}\nand the query: \"{query}\". Respond with 'Yes' if the document is relevant to the query or 'No' if not.", "{judgment}"),
        ("Investigate the relationship between the document:\n{document}\nand query - {query}. Ascertain the document's relevance to the given query, providing a definitive response of 'Yes' if the document is relevant to the query or 'No' if not.", "{judgment}"),
        ("Explore the contents of the provided document:\n{document}\nFormulate a query that encapsulates the information presented. Return the generated query.", "{query}"),
        ("Delve into the information within the provided document:\n{document}\nGenerate a query that succinctly captures the essence of the document. Return the formulated query.", "{query}"),
        ("Consider a query \"{query}\" alongside two documents:\n{document}\nDecide which document is more relevant to the given query by providing the corresponding document identifier.", "{identifier}"),
        ("Check a query: \"{query}\" in conjunction with two documents:\n{document}\neach with a unique identifier. Determine the document identifier corresponding to the more relevant document for the given query.", "{identifier}"),
        ("Given a query:\"{query}\" and two documents:\n{document}\nHere is a hypothesis: the {num} document is more relevant to the given query. Determine that hypothesis by producing 'Yes' if the hypothesis is true or 'No' if it is false.", "{judgment}"),
        ("Evaluate the hypothesis suggesting that, given a query - \"{query}\" and two documents:\n{document}\nthe document labeled {num} is more relevant. Confirm or deny this hypothesis by responding with 'Yes' if the hypothesis is true or 'No' if it's false.", "{judgment}"),
        ("Here are some documents:\n{document}\nand a query \"{query}\", and each document is indicated by a number identifier. Please sort the documents in an order based on their relevance to the above query by returning an identifier list. Be careful to sort documents in order of their relevance to the query from highest to lowest.", "{identifier}"),
        ("Organize the documents:\n{document}\naccording to their relevance to the provided query \"{query}\". Return the list of identifiers, indicating the order of decreasing relevance.", "{identifier}"),
        ("Here are some documents:\n{document}\nand a query \"{query}\", and each document is indicated by a number identifier. Here is an identifiers list:\n{identifier}\nDetermine if the list is ranked from highest to lowest by the relevance of the documents to the given query. If so, return 'Yes', otherwise 'No'.", "{judgment}"),
        ("Examine a query:\"{query}\" alongside some documents:\n{document}\neach marked with a unique identifier. Utilizing the provided list of identifiers:\n{identifier}\nDetermine whether the list accurately ranks the documents from highest to lowest relevance to the given query, and respond with 'Yes' if so or 'No' if not.", "{judgment}")
    ],
    "biomedical-retrieval-trec-covid": [
        ("Document: {document}\n\nQuery: {query}\n\nAssess the relevance of the provided document in the context of the COVID-19-related query. Answer 'Yes' if the document explicitly addresses or pertains to the query, or 'No' if it is unrelated.", "{judgment}"),
        ("Here is a document related to COVID-19:\n{document}\nand a corresponding query: \"{query}\". Evaluate the relevance between the document and the query. Provide your assessment by answering with either 'Yes' for relevance or 'No' for irrelevance.", "{judgment}"),
        ("Given the document on COVID-19:\n{document}\nCreate a query that directly relates to its content.", "{query}"),
        ("Given the provided document on COVID-19:\n{document}\nFormulate a query that aligns with the information detailed in the document.", "{query}"),
        ("Given a query: \"{query}\" and two documents:\n{document}\nEach marked with a unique identifier and related to COVID-19, assess and identify which document is more closely related to the query. Respond with the identifier of the more relevant document.", "{identifier}"),
        ("Evaluate the relevance of two documents:\n{document}\nBoth concerning COVID-19, against the query: \"{query}\". Provide the identifier of the document that is more pertinent to the query and return the identifier.", "{identifier}"),
        ("Given the query: \"{query}\" and two documents related to COVID-19:\n{document}\nAssess the hypothesis that the document numbered {num} is more relevant to the query. Confirm or refute this hypothesis by responding with 'Yes' for agreement or 'No' for disagreement.", "{judgment}"),
        ("For the two documents:\n{document}\nExamine the hypothesis stating that the {num} document has greater relevance to the specified query: \"{query}\". Conclude the assessment with either 'Yes' if the hypothesis is correct or 'No' if it is incorrect.", "{judgment}"),
        ("Given several documents:\n{document}\neach pertaining to COVID-19, and a specific query: \"{query}\", organize the documents in order of relevance to the query. List the identifiers of these documents starting from the most relevant to the least relevant.", "{identifier}"),
        ("Rank the documents:\n{document}\nall related to COVID-19, in order of their relevance to the specified query: \"{query}\". The ranking should start with the most relevant document. Output this ranking as a list of the documents' identifiers, from highest to lowest relevance.", "{identifier}"),
        ("Given the COVID-19 documents:\n{document}\nand a query:\"{query}\", each document is labeled with a unique number. You are provided with a list of these numbers:\n{identifier}\nEvaluate if the documents in the list are ordered from the most to the least relevant in relation to the query. If the order is from highest to lowest relevance, return yes, otherwise return no.", "{judgment}"),
        ("For the query:\"{query}\" and provided COVID-19 documents:\n{document}\neach with a unique numerical identifier, and a given list of these identifiers:\n{identifier}\nDetermine if the documents are ranked in descending order of relevance to the query. Indicate your assessment by answering 'Yes' if this is true or 'No' if not.", "{judgment}")
    ],
    "biomedical-retrieval-nfcorpus": [
        ("Assess the relevance of the medical document:\n{document}\nin relation to the search query \"{query}\". Determine if the document is relevant by responding with 'Yes' for relevance or 'No' for irrelevance.", "{judgment}"),
        ("Assess the relevance of this medical document to a specific query.\nDocument:\n{document}\nQuery:\n\"{query}\"\nIs the document relevant to the query? Respond with 'Yes' for relevance or 'No' for irrelevance.", "{judgment}"),
        ("Create a search query that matches the context of the given medical document.\nDocument:\n{document}\nGenerate a query that accurately reflects the main themes or topics of the document.", "{query}"),
        ("Formulate a search query that closely relates to the content of the specified medical field document.\nDocument:\n{document}\nDesign a query that effectively captures the key information or themes presented in the document.", "{query}"),
        ("Assess which of the two medical field documents is more relevant to the provided query \"{query}\". Each document is presented with a unique identifier.\nDocuments:\n{document}\nIdentify and return the identifier of the document that best aligns with the query.", "{identifier}"),
        ("Evaluate which one of the two medical field documents is more pertinent to the search query \"{query}\". Each document has a unique identifier.\nDocuments:\n{document}\nSelect and return the identifier of the document that demonstrates greater relevance to the query.", "{identifier}"),
        ("Review the provided query \"{query}\" and two medical field documents:\n{document}\neach with a unique identifier. You are given a hypothesis:\n\"The document with identifier '{num}' is more relevant to the query.\"\nRespond with 'Yes' or 'No' to assess the accuracy of this hypothesis. Note that if the hypothesis is correct, return 'Yes', otherwise return 'No'.", "{judgment}"),
        ("Considering the query \"{query}\" and two medical field documents:\n{document}\nexamine the hypothesis stating \"The document with identifier '{num}' is more relevant to the query.\" Determine the validity of this hypothesis and indicate your conclusion by responding with either 'Yes' or 'No'. Note that if the hypothesis is correct, return 'Yes', otherwise return 'No'.", "{judgment}"),
        ("Arrange the given medical field documents:\n{document}\nin order of relevance to the specified query \"{query}\", with the most relevant document at the top and the least relevant at the bottom. Use their unique number identifiers to indicate the sequence of relevance.", "{identifier}"),
        ("Sort the provided medical field documents:\n{document}\nin a list according to their relevance to the query \"{query}\". Begin with the document that is most relevant and conclude with the least relevant. Use the respective number identifiers of each document to denote their order of relevance.", "{identifier}"),
        ("Assess the sequence of medical field documents:\n{document}\nin reference to the query \"{query}\", where each document has a number identifier. Given a list of these identifiers:\n{identifier}\nEvaluate if they are correctly ordered from most to least relevant in relation to the query. Answer with 'Yes' for correcness or 'No' for incorrectness.", "{judgment}"),
        ("Given the query \"{query}\" and a set of medical field documents:\n{document}\neach assigned a unique identifier, and an existing list of these identifiers:\n{identifier}\nevaluate if the list accurately ranks the documents from most to least relevant in relation to the query. Answer with 'Yes' if so or 'No' if not.", "{judgment}")
    ],
    "supporting-evidence-retrieval-nq": [
        ("Review the content of the document:\n{document}\nand ascertain its relevance to the topic: \"{query}\". Provide your determination by responding with either 'Yes' for relevance or 'No' for irrelevance.", "{judgment}"),
        ("Examine the given document:\n{document}\nand the query \"{query}\". You are presented with a statement: The document is relevant to the query. Assess the accuracy of this statement and respond with either 'Yes' or 'No' to indicate whether the judgment is correct or incorrect.", "{judgment}"),
        ("Review the given document:\n{document}\nand create a search query that is closely related to the content of the document.", "{query}"),
        ("Examine the document:\n{document}\nand develop a search query that is directly related to the information contained within the document.", "{query}"),
        ("Evaluate the relevance of the provided query \"{query}\" to a pair of documents:\n{document}\neach identified separately. Determine which document is more relevant to the query and return the identifier of the more relevant document.", "{identifier}"),
        ("Analyze the query \"{query}\" along with two documents:\n{document}\neach with its identifier. Select the document identifier that is of greater relevance to the provided query.", "{identifier}"),
        ("Evaluate the query \"{query}\" and two documents:\n{document}\neach assigned a unique identifier. You are provided with a hypothesis: The document labeled as \"{num}\" is more relevant. Determine the correctness of this hypothesis and respond with 'Yes' for correctness or 'No' for incorrectness.", "{judgment}"),
        ("Assess the query \"{query}\" and the paired documents:\n{document}\nYou are presented with a hypothesis: The document labeled as \"{num}\" is more relevant to the query. Provide your judgment by responding with 'Yes' or 'No' to ascertain the accuracy of this hypothesis. 'Yes' means the hypothesis is correct, and 'No' means incorrect.", "{judgment}"),
        ("Arrange the provided documents:\n{document}\nin accordance with their relevance to the specified query \"{query}\". Utilize number identifiers to denote the sequence of relevance, with the most relevant document at the top and the least relevant document at the end.", "{identifier}"),
        ("Evaluate the relevance of the given documents:\n{document}\nin relation to the provided query \"{query}\". Arrange them in descending order of relevance, using number identifiers for output, with the most relevant documents positioned at the top.", "{identifier}"),
        ("Examine the query \"{query}\" and the set of documents:\n{document}\neach distinguished by a unique identifier. Evaluate the provided identifier list \"{identifier}\" to determine if it correctly orders the documents from the highest to lowest relevance with respect to the specified query. If it is indeed in order of relevance from highest to lowest, return 'Yes', else return 'No'.", "{judgment}"),
        ("With the query \"{query}\" and a collection of documents:\n{document}\nwhere each document is assigned a unique identifier, and an associated list of these identifiers:\n{identifier}\nAssess whether the list accurately represents the order of documents from the most to least relevant to the query. If it does, return 'Yes', otherwise return 'No'.", "{judgment}")
    ],
    "supporting-evidence-retrieval-fiqa": [
        ("Evaluate the financial document:\n{document}\nin the context of the query: \"{query}\". Determine if the document is relevant to the query and provide your judgment with 'Yes' for relevance or 'No' for irrelevance.", "{judgment}"),
        ("Examine the financial document:\n{document}\nand the query: \"{query}\". Determine whether the document is relevant to the query and indicate your judgment with either 'Yes' for relevance or 'No' for irrelevance.", "{judgment}"),
        ("Review the financial document:\n{document}\nand create a query that is closely related to the information contained within the document.", "{query}"),
        ("Formulate a query that is directly related to the content of the financial document:\n{document}", "{query}"),
        ("Evaluate the relevance of the query: \"{query}\" and the pair of financial documents:\n{document}\neach assigned a unique identifier. Determine which document is more relevant to the provided query and specify its document identifier.", "{identifier}"),
        ("Evaluate the relevance of the query: \"{query}\" to the pair of financial documents:\n{document}\neach distinguished by an identifier. Clearly indicate which document is more relevant to the query by specifying its document identifier.", "{identifier}"),
        ("Analyze the query: \"{query}\" along with two financial documents:\n{document}\nYou are presented with a hypothesis: The {num} document is more relevant to the query. Assess the accuracy of this hypothesis and respond with either 'Yes' for accuracy or 'No' for inaccuracy.", "{judgment}"),
        ("Examine the connection between the query: \"{query}\" and the two financial documents:\n{document}\nGiven the hypothesis that the {num} document is more relevant, assess the accuracy of this hypothesis and provide your judgment by responding with 'Yes' if the hypothesis is true or 'No' if false. ", "{judgment}"),
        ("Assess the relevance of the query: \"{query}\" to a set of financial documents:\n{document}\nGenerate a list of document identifiers, arranging them from the most relevant to the least relevant in relation to the query, and return the identifiers list.", "{identifier}"),
        ("Evaluate the relevance of the provided financial documents:\n{document}\nto the query: \"{query}\". Generate a list of document identifiers, arranging them in descending order to reflect their relevance to the provided query, and return the identifiers list.", "{identifier}"),
        ("Examine the relevance of the financial documents:\n{document}\nto the query: \"{query}\". Given the provided list of identifiers:\n{identifier}\nassess whether this list correctly orders the documents from the highest to lowest relevance, and respond with 'Yes' or 'No'. If it is indeed arranged this way, return 'Yes', otherwise return 'No'.", "{judgment}"),
        ("Considering the query: \"{query}\" and a collection of financial documents:\n{document}\neach labeled with number identifiers, along with a list of identifiers:\n{identifier}\nEvaluate if the list accurately represents the order of documents from highest to lowest relevance to the provided query. Provide your judgment with either 'Yes' or 'No'. If the correlation is indeed highest to lowest, return 'Yes', otherwise return 'No'.", "{judgment}")
    ],
    "supporting-evidence-retrieval-hotpot-qa": [
        ("Analyze the relationship between the document:\n{document}\nand the query: \"{query}\". Offer a definitive response by indicating whether they are relevant, and reply with either 'Yes' for relevance or 'No' for irrelevance. Reply: ", "{judgment}"),
        ("Provide a judgment regarding the relevance of the given document:\n{document}\nto the provided query: \"{query}\". State 'Yes' or 'No' based on their correlation. Return 'Yes' if relevant and 'No' if not.", "{judgment}"),
        ("Generate a query that aligns with the information presented in the provided document:\n{document}", "{query}"),
        ("Create a query that corresponds to the content presented in the provided document:\n{document}", "{query}"),
        ("Compare the relevance of two documents:\n{document}\nto the provided query: \"{query}\". Identify the document with the higher relevance by specifying its identifier.", "{identifier}"),
        ("Evaluate the relevance of the two documents:\n{document}\nin the context of the query: \"{query}\". Select the identifier of the document that is more relevant to the provided query based on their relevance.", "{identifier}"),
        ("Here are two documents with their own identifiers:\n{document}\nAssess the correctness of the hypothesis proposing that document {num} is more relevant to the provided query: \"{query}\" than another document. Provide a clear response of 'Yes' if indeed more relevant or 'No' if not.", "{judgment}"),
        ("Given the query: \"{query}\" and two documents:\n{document}\nDetermine if document {num} is more relevant. Respond with 'Yes' if indeed more relevant or 'No' if not.", "{judgment}"),
        ("Rank the following documents in descending order of relevance to the query: \"{query}\"\n{document}\nProvide the list of identifiers.", "{identifier}"),
        ("Given the query: \"{query}\" and a list of documents:\n{document}\nSort the documents in descending order of relevance and return the resulting list of identifiers.", "{identifier}"),
        ("Given a set of documents: {document}, each with a unique identifier, and the list of identifiers: {identifier}, evaluate the hypothesis that this list ranks the documents in descending order of relevance to the query: \"{query}\". Provide a response of 'Yes' for correct hypothesis or 'No' for incorrect hypothesis.", "{judgment}"),
        ("Examine a query:\"{query}\" and some documents:\n{document}\neach with its own identifier. Given the list of identifiers:\n{identifier}\nDetermine whether the list accurately ranks the documents from highest to lowest relevance to the given query, and respond with 'Yes' if this is indeed the correct order or 'No' if not.", "{judgment}")
    ],
    "argument-retrieval-arguana": [
        ("Document:\n\n{document}\n\nQuery:\n\n{query}\n\nDetermine their relevance and return the judgment about the document's relevance to the query by responding with either 'Yes' for relevance or 'No' for irrelevance.", "{judgment}"),
        ("Assess the relevance between the document and query provided:\n{document}\nQuery:{query}Respond with 'Yes' if the document is relevant to the query, and 'No' if it is not.", "{judgment}"),
        ("Document:\n{document}\nPlease formulate a query that is aligned with the document's argument.", "{query}"),
        ("Create a query that is relevant to the arguement in the document:\n{document}", "{query}"),
        ("Given a query \"{query}\" and two documents:\n{document}\nwith unique identifiers, decide which document's argument is more relevant to the query and output its corresponding identifier.", "{identifier}"),
        ("Evaluate the relevance of two documents:\n{document}\nto the provided query \"{query}\". Express the identifier of the document that is more relevant to the query.", "{identifier}"),
        ("Given a query \"{query}\" and two documents:\n{document}\nAssess the hypothesis that the {num} document's argument is more relevant to the query. Judge the hypothesis by choosing either 'Yes' if this hypothesis is true or 'No' if false.", "{judgment}"),
        ("Here are two documents:\n{document}\nExamine the hypothesis that the argument in the {num} document is more relevant to the provided query \"{query}\". Return the judgment by choosing 'Yes' if the hypothesis is true or 'No' if not.", "{judgment}"),
        ("Rank some documents:\n{document}\n in descending order of relevance to the provided query: \"{query}\". Return the list of identifiers associated with each document in order.", "{identifier}"),
        ("Given a query \"{query}\" and some documents:\n{document}\nThese documents are identified by numbers. Please rerank these documents in descending order according to their relevance to the given query. Return a sorted list with the identifiers.", "{identifier}"),
        ("Here is a query: \"{query}\". There are some documents:\n{document}\nEach document has its unique identifier. Now, given an identifiers list {identifier}, determine if the order in the list accurately reflects the descending relevance of the documents to the provided query by responding with either 'Yes' if so or 'No' if not.", "{judgment}"),
        ("Provided a query: \"{query}\" and some documents:\n{document}\nEach document has a distinct identifier. Examine whether the order of the identifiers list {identifier} indicates the relevance of the documents related to the query from high to low by responding with either 'Yes' if the relevance is from high to low or 'No' if not.", "{judgment}")
    ],
    "argument-retrieval-touche": [
        ("Evaluate the relevance between the given document on controversial subjects:\n{document}\nand the query: \"{query}\", and provide a clear 'Yes' for relevance or 'No' for irrelevance judgment regarding their relevance.", "{judgment}"),
        ("Determine the relevance between the given document on controversial subjects:\n{document}\nand the query: \"{query}\". Indicate the relevance with either 'Yes' for relevance or 'No' for irrelevance.", "{judgment}"),
        ("Review the contents of the document on some controversial topics:\n{document}\nand formulate a query that covers the information presented.", "{query}"),
        ("Generate a query related to the provided document:\n{document}\nbased on the content within the document.", "{query}"),
        ("Given a query: \"{query}\" and two documents:\n{document}\neach with its unique identifier, determine which document is more relevant to the given query by providing the document identifier.", "{identifier}"),
        ("Compare the relevance of two documents:\n{document}\nto the query: \"{query}\", and specify the document identifier that has higher relevance.", "{identifier}"),
        ("Given a query:\"{query}\" and two documents:\n{document}\nConsider the hypothesis that the {num} document is more relevant to the query. Confirm or deny this hypothesis with a response of 'Yes' or 'No'. Return 'Yes' if confirm the hypothesis or 'No'.", "{judgment}"),
        ("Evaluate the following hypothesis: Given two documents:\n{document}\nwith distinct identifiers, the document labeled {num} is more relevant to the given query: \"{query}\". Provide a 'Yes' or 'No' response. If the hypothesis is correct, return 'Yes', else return 'No'.", "{judgment}"),
        ("Rerank some provided documents on a controversial topic:\n{document}\nbased on their relevance to the query \"{query}\". Return a list of identifiers in the order of descending relevance.", "{identifier}"),
        ("Sort the documents on a controversial topic:\n{document}\nbased on their relevance to the given query: \"{query}\", listing the identifiers in the order of decreasing relevance.", "{identifier}"),
        ("Examine a query: \"{query}\" alongside some documents:\n{document}\neach marked with a unique identifier. Given the provided list of identifiers:\n{identifier}\nDetermine whether the list accurately ranks the documents from highest to lowest relevance to the given query, and respond with 'Yes' if this correlation order is true or 'No' if not.", "{judgment}"),
        ("Assess the accuracy of the provided list of identifiers:\n{identifier}\nin ranking some documents:\n{document}\nfrom highest to lowest relevance to the given query: \"{query}\". Provide a 'Yes' or 'No' response. Notice if this sort is correct, return 'Yes', else return 'No'.", "{judgment}")
    ],
    "duplicate-question-retrieval-cqadupstack": [
        ("Evaluate the relevance between the given document on controversial subjects:\n{document}\nand the query: \"{query}\", and provide a clear 'Yes' for relevance or 'No' for irrelevance judgment regarding their relevance.", "{judgment}"),
        ("Determine the relevance between the given document on controversial subjects:\n{document}\nand the query: \"{query}\". Indicate the relevance with either 'Yes' for relevance or 'No' for irrelevance.", "{judgment}"),
        ("Review the contents of the document on some controversial topics:\n{document}\nand formulate a query that covers the information presented.", "{query}"),
        ("Generate a query related to the provided document:\n{document}\nbased on the content within the document.", "{query}"),
        ("Given a query: \"{query}\" and two documents:\n{document}\neach with its unique identifier, determine which document is more relevant to the given query by providing the document identifier.", "{identifier}"),
        ("Compare the relevance of two documents:\n{document}\nto the query: \"{query}\", and specify the document identifier that has higher relevance.", "{identifier}"),
        ("Given a query: \"{query}\" and two documents:\n{document}\nConsider the hypothesis that the {num} document is more relevant to the query. Confirm or deny this hypothesis with a response of 'Yes' or 'No'. Return 'Yes' if confirm the hypothesis or 'No'.", "{judgment}"),
        ("Evaluate the following hypothesis: Given two documents:\n{document}\nwith distinct identifiers, the document labeled {num} is more relevant to the given query: \"{query}\". Provide a 'Yes' or 'No' response. If the hypothesis is correct, return 'Yes', else return 'No'.", "{judgment}"),
        ("Rerank some provided documents on a controversial topic:\n{document}\nbased on their relevance to the query \"{query}\". Return a list of identifiers in the order of descending relevance.", "{identifier}"),
        ("Sort the documents on a controversial topic:\n{document}\nbased on their relevance to the given query: \"{query}\", listing the identifiers in the order of decreasing relevance.", "{identifier}"),
        ("Examine a query: \"{query}\" alongside some documents:\n{document}\neach marked with a unique identifier. Given the provided list of identifiers:\n{identifier}\nDetermine whether the list accurately ranks the documents from highest to lowest relevance to the given query, and respond with 'Yes' if this correlation order is true or 'No' if not.", "{judgment}"),
        ("Assess the accuracy of the provided list of identifiers:\n{identifier}\nin ranking some documents:\n{document}\nfrom highest to lowest relevance to the given query:\"{query}\". Provide a 'Yes' or 'No' response. Notice if this sort is correct, return 'Yes', else return 'No'.", "{judgment}")
        ],
    "duplicate-question-retrieval-quora": [
        ("Determine the relevance between the document:\n{document}\nand the query: {query}. Judge whether they are related by responding with 'Yes' for relevance or 'No' for irrelevance.", "{judgment}"),
        ("Analyze the alignment of the document's content:\n{document}\nwith the query \"{query}\". Conclude with a 'Yes' if they align or a 'No' if they don't.", "{judgment}"),
        ("Inspect the document:\n{document}\nand derive a related question that matches its content. Formulate the related query.", "{query}"),
        ("Study the document:\n{document}\nand generate a query that reflects the information within. State the created query.", "{query}"),
        ("With a given query: \"{query}\" and two unique documents:\n{document}\nIdentify the document that aligns more closely with the query by stating its identifier.", "{identifier}"),
        ("Evaluate a query:\"{query}\" alongside two distinct documents:\n{document}\nChoose the document that is more relevant to the query and provide its identifier.", "{identifier}"),
        ("Assess if the document labeled {num} in the set of two documents:\n{document}\nis more relevant to the query: \"{query}\". Confirm or deny this with a 'Yes' or 'No' response.", "{judgment}"),
        ("Test the hypothesis that, among two documents:\n{document}\nthe one identified as {num} is more pertinent to the query: \"{query}\". Validate this with a 'Yes' if the hypothesis is true or 'No' if false answer.", "{judgment}"),
        ("Rank several documents:\n{document}\nby their relevance to the query: \"{query}\" in descending order. List their identifiers.", "{identifier}"),
        ("Organize various documents:\n{document}\naccording to their relevance to the query: {query}, listing them from most to least relevant.", "{identifier}"),
        ("Verify if the list of identifiers:\n{identifier}\ncorrectly ranks the documents:\n{document}\nin terms of their relevance to the query: \"{query}\" from highest to lowest. Provide a 'Yes' for accuracy or 'No' for inaccuracy.", "{judgment}"),
        ("Review the list of identifiers:\n{identifier}\nin relation to documents:\n{document}\nand a query: \"{query}\". Determine if the list accurately orders the documents from highest relevance to lowest relevance, answering with 'Yes' if so or 'No' if not.", "{judgment}")
    ],
    "entity-retrieval-dbpedia": [
        ("Determine the relevance of the document:\n{document}\n to the query: \"{query}\". Conclude with 'Yes' for relevance or 'No' for irrelevance.", "{judgment}"),
        ("Evaluate whether the document:\n{document}\n is relevant to the specified query: {query}. Provide a verdict expressed as 'Yes' if relevant or 'No' if irrelevant.", "{judgment}"),
        ("Generate a query relevant to the document presented:\n{document}", "{query}"),
        ("Create a query that corresponds to the given document:\n{document}", "{query}"),
        ("Given a query: \"{query}\" and two documents:\n{document}\neach identified by a distinct number. Determine the document identifier for the one more relevant to the provided query.", "{identifier}"),
        ("Evaluate two documents:\n{document}\nwith unique identifiers in the context of a query: \"{query}\". Indicate which document is more relevant and provide its identifier.", "{identifier}"),
        ("Examine a hypothesis suggesting that, given a query \"{query}\" and two documents:\n{document}\nthe document labeled as {num} holds greater relevance. Judge this hypothesis by responding with 'Yes' if the hypothesis is true or 'No' if false.", "{judgment}"),
        ("Analyse this hypothesis:\nIn the context of a query \"{query}\" and two documents:\n{document}\nthe {num} document has higher relevance about the query.\nDetermine this hypothesis with a response of 'Yes' if it is true or 'No' if it's false.", "{judgment}"),
        ("Rank some documents:\n{document}\nbased on their relevance to the specified query \"{query}\". Return the list of identifiers in descending order.", "{identifier}"),
        ("Arrange some documents:\n{document}\nin descending order of relevance to the given query: {query}. Provide the identifier list with the most relevant first and the least relevant last.", "{identifier}"),
        ("Assess the ranking of some documents:\n{document}\nin relation to the provided query: \"{query}\". The given identifiers list is: \n{identifier}\nJudge whether the list is correctly ordered from highest to lowest relevance. Respond with either 'Yes' if the order is indeed that or 'No' if not.", "{judgment}"),
        ("Evaluate the set of documents:\n{document}\nconcerning the given query: \"{query}\". Check the list of identifiers:\n{identifier}\nDetermine the accuracy of the ranking by relevance from highest to lowest and reply with 'Yes' or 'No'. If it is sorted by relevance from highest to lowest, return 'Yes', else return 'No'.", "{judgment}")
    ],
    "article-retrieval-scidocs": [
        ("Determine the correlation between the provided literature-related document:\n{document}\nand the query: \"{query}\". Conclude if they are closely connected with a 'Yes' for relevance or 'No' for irrelevance.", "{judgment}"),
        ("Evaluate whether the scientific document:\n{document}\nis strongly relevant to the query: \"{query}\". Respond with 'Yes' if it is relevant or 'No' if it is not.", "{judgment}"),
        ("Examine the document:\n{document}\nand create a query that is derived from its contents.", "{query}"),
        ("Study the document:\n{document}\nand develop a query that reflects its content.", "{query}"),
        ("Given a query:\"{query}\" and two literature-related documents:\n{document}\neach with a unique identifier, identify which document is more relevant to the query by specifying its identifier.", "{identifier}"),
        ("Compare two documents:\n{document}\nagainst a query:\"{query}\" and decide which document, identified by its unique identifier, is more relevant.", "{identifier}"),
        ("Judge the hypothesis that for a given query:\"{query}\" and two scientific documents:\n{document}\nthe document labeled {num} is more relevant. Respond with 'Yes' for agreement or 'No' for disagreement.", "{judgment}"),
        ("Test the hypothesis that among two documents:\n{document}\nthe one marked as {num} is more relevant to the query:\"{query}\". Confirm or refute with 'Yes' or 'No'.", "{judgment}"),
        ("Rank the documents:\n{document}\nin order of their relevance to the query: {query}. List the identifiers starting with the most relevant document.", "{identifier}"),
        ("Sort the provided literature-related documents:\n{document}\nbased on how relevant they are to the query: \"{query}\". List the identifiers in descending order of relevance.", "{identifier}"),
        ("Evaluate if the given list of identifiers:\n{identifier}\ncorrectly ranks the documents:\n{document}\nin order of their relevance to the query: \"{query}\" from highest relevance to lowest relevance. Respond with 'Yes' for accuracy or 'No' for inaccuracy.", "{judgment}"),
        ("Review the ranking of documents:\n{document}\n by their relevance to the query:\"{query}\" using the provided list of identifiers:\n{identifier}\nConfirm the accuracy of the ranking with 'Yes' or 'No'. If the list is sorted from highest relevance to lowest relevance, return 'Yes', else return 'No'.", "{judgment}")
    ],
    "fact-retrieval-climate-fever": [
        ("Analyze the correlation between this document on the topic of climate change:\n{document}\nand the following query: {query}. Determine if the document is relevant to the query. Respond with 'Yes' for relevance or 'No' for irrelevance.", "{judgment}"),
        ("Evaluate the document's relevance to the query on climate change:\n{document}\nagainst this query: \"{query}\" by exploring their connection. Conclude with 'Yes' for relevance or 'No' for irrelevance.", "{judgment}"),
        ("Investigate the document on climate change:\n{document}\nand develop a query that aligns with its content.", "{query}"),
        ("Formulate a query that corresponds to the information in this climate change document:\n{document}", "{query}"),
        ("Given this query:\"{query}\" and two climate change documents:\n{document}\neach with a unique identifier, identify which document aligns more closely with the query by indicating the document's identifier.", "{identifier}"),
        ("Compare the relevance of two climate change documents:\n{document}\nto this query: \"{query}\" and identify the document with greater relevance by its identifier.", "{identifier}"),
        ("With a query: \"{query}\" and two documents on climate change:\n{document}\nevaluate whether the document labeled {num} is more relevant to the query. Answer with 'Yes' if it is more relevant or 'No' if not.", "{judgment}"),
        ("Test the hypothesis that in two documents:\n{document}\nthe one labeled {num} is more relevant to the query: \"{query}\". Confirm or deny this with 'Yes' or 'No'.", "{judgment}"),
        ("Rerank these climate change documents:\n{document}\nby their relevance to the query: \"{query}\" and list the identifiers. Rank from most to least relevant.", "{identifier}"),
        ("Sort these climate change documents:\n{document}\n based on their relevance to the query: \"{query}\". List the identifiers in order of relevance, starting with the most relevant and ending with the most irrelevant.", "{identifier}"),
        ("Review this query: \"{query}\" and the climate change documents:\n{document}\nConfirm if the provided list of identifiers: {identifier} correctly ranks the documents in order of relevance to the query from highest to lowest. Respond with 'Yes' if so or 'No' if not.", "{judgment}"),
        ("Evaluate if the given list of identifiers:\n{identifier}\naccurately ranks these documents:\n{document}\nin order of relevance to the query: \"{query}\". Answer with 'Yes' if it's in order of relevance from highest to lowest or 'No' if not.", "{judgment}")
    ],
    "fact-retrieval-fever": [
        ("Assess the relationship between the given document:\n{document}\nand the query: \"{query}\" to determine if the document is relevant. Answer with 'Yes' for relevance or 'No' for irrelevance.", "{judgment}"),
        ("Review the provided document:\n{document}\nin relation to the query: \"{query}\" and decide if there is relevance. Respond with 'Yes' if it is relevant or 'No' if it is not.", "{judgment}"),
        ("Using the content of the provided document:\n{document}\nGenerate a query that closely aligns with the document's subject.", "{query}"),
        ("Develop a query that is in line with the subject matter of the provided document:\n{document}", "{query}"),
        ("Evaluate two documents:\n{document}\nagainst a given query: \"{query}\" and identify the document that is more relevant by its identifier.", "{identifier}"),
        ("With a query \"{query}\" and two documents:\n{document}\nascertain which document is more relevant and provide its identifier.", "{identifier}"),
        ("Test the hypothesis regarding the relevance of two documents:\n{document}\nto a query \"{query}\", determining if the document labeled {num} is more pertinent. Respond with 'Yes' if the hypothesis is true or 'No' if false.", "{judgment}"),
        ("Assess the hypothesis that, given a query:\"{query}\" and two documents:\n{document}\nthe document labeled {num} is more relevant. Provide your judgment with 'Yes' if the hypothesis is correct or 'No' if not.", "{judgment}"),
        ("Rank a set of documents:\n{document}\nby their relevance to a query: \"{query}\". List their identifiers in order of decreasing relevance.", "{identifier}"),
        ("Organize a collection of documents:\n{document}\nbased on their relevance to the query: \"{query}\", and list them in descending order of relevance.", "{identifier}"),
        ("Verify if the list of identifiers:\n{identifier}\naccurately represents the ranking of documents:\n{document}\nin terms of their relevance to the query \"{query}\" from the highest relevance to the lowest relevance. Answer with 'Yes' for accuracy or 'No' for inaccuracy.", "{judgment}"),
        ("Review a list of identifiers:\n{identifier}\nalongside documents:\n{document}\nand a query: {query}. Assess if the list correctly ranks the documents in terms of relevance from high to low according to the query and respond with 'Yes' if so or 'No' if not.", "{judgment}")
    ],
    "fact-retrieval-scifact": [
        ("Assess the relevance between the scientific document:\n{document}\nand query: \"{query}\", and state 'Yes' or 'No' to reflect the relevance judgment. Answer 'Yes' for relevance and 'No' for irrelevance.", "{judgment}"),
        ("Determine the relevance of the given scientific document:\n{document}\nto the query: \"{query}\". Respond with 'Yes' or 'No' to indicate relevance. If they are relevant, return 'Yes', else return 'No'.", "{judgment}"),
        ("Generate a query that aligns with the key information in the given scientific document:\n{document}", "{query}"),
        ("Return a query that reflects the main content of the supplied scientific document:\n{document}", "{query}"),
        ("Analyze the relevance of two scientific documents:\n{document}\nto the query: \"{query}\" and identify the more relevant document by its identifier.", "{identifier}"),
        ("Compare the relevance of two scientific documents:\n{document}\nagainst the query: {query} and specify the identifier of the more relevant document.", "{identifier}"),
        ("For two scientific documents:\n{document}\nEvaluate the hypothesis that the document labeled {num} is more relevant to the provided query: \"{query}\" than the other. Respond with 'Yes' if the hypothesis is correct or 'No' if incorrect.", "{judgment}"),
        ("Hypothesize that between two scientific documents:\n{document}\n and a query: {query}, the document labeled {num} is more relevant. Confirm or refute with 'Yes' or 'No'.", "{judgment}"),
        ("Order the provided scientific documents:\n{document}\n based on their relevance to the query: \"{query}\", from most to least relevant. Only output a list of identifiers.", "{identifier}"),
        ("Organize some documents:\n{document}\nby their relevance to the provided query: {query}, listing the identifiers from highest to lowest relevance.", "{identifier}"),
        ("Here are some documents:\n{document}\nwith unique identifiers and a query: \"{query}\". Given an identifier list:\n{identifier}\nAssess the accuracy of the list in ranking those documents from highest to lowest relevance to the provided query. Provide a conclusive 'Yes' or 'No' judgment. If indeed it's ranked from highest to lowest by correlation, return 'Yes', else return 'No'.", "{judgment}"),
        ("Examine a query: \"{query}\" alongside some documents:\n{document}\neach with its own identifier. Give a list of identifiers:\n{identifier}\nDetermine if the list accurately ranks the documents from the most to the least relevant to the given query, and reply with 'Yes' if the list given is in the correct order or 'No' if not.", "{judgment}")
    ]
}

PATTERNS_FOR_FEW_SHOT_DEMONSTRATIONS = {
    "query-description-gov2": [
        ("{title}\n\nWhat is the search target of the above query? Answer: ", "{narrative}"),
        ("For the query \"{title}\", the search target is: ", "{narrative}"),
        ("What type of thing is the query \"{title}\" searching for? Answer: ", "{narrative}"),
        ("What is {title} about? Answer: ", "{narrative}"),
        ("{title}\n\nGenerate an explanation about the above query's intent. Result: ", "{narrative}"),
        ("Given the query {title}, describe what kind of documents are relevant. Result: ", "{narrative}"),
        ("Describe some possible relevant documents about the search target {title}. Result: ", "{narrative}"),
        ("What is the search intent about the query {title}? Answer: ", "{narrative}"),
        ("Describe the search intent of the given query \"{title}\". Result: ", "{narrative}"),
        ("Return the search intent for the following query:\n\n{title}\n\nIntent: ", "{narrative}"),
        ("Referring to this description that describes the documents relevant to a query\n\n{narrative}\n\nplease infer the corresponding query. Query: ", "{title}"),
        ("{narrative}\n\nWhat is a possible query for these documents? Answer: ", "{title}")
    ],
    "query-description-trec-robust": [
        ("{title}\n\nWhat kind of documents are relevant to the above query? Answer: ", "{narrative}"),
        ("For the query \"{title}\", the relevant document is: ", "{narrative}"),
        ("What type of documents is the query {title} intended to search for? Answer: ", "{narrative}"),
        ("Tell me what is \"{title}\" seeking for? Answer: ", "{narrative}"),
        ("{title}\n\nThe above query is in search of what kind of things? Answer: ", "{narrative}"),
        ("Describe the document about the search target of the query \"{title}\". Result: ", "{narrative}"),
        ("The query {title} is aiming to find some documents. Describe the relevant documents: ", "{narrative}"),
        ("Identify potential documents relevant to the query {title}. Result: ", "{narrative}"),
        ("{title}\n\nWhat is the query above attempting to discover? Answer: ", "{narrative}"),
        ("Here's the query:\n{title}\nCould you suggest some documents that are relevant to this topic? Answer: ", "{narrative}"),
        ("Seeking for documents like\n\n{narrative}\n\nHow to formulate a query? Query: ", "{title}"),
        ("Give me a query to find such documents\n\n{narrative}\n\nQuery: ", "{title}")
    ],
    "query-description-trec-covid": [
        ("{title}\n\nPlease identify the specific medical topic or subject inquired about in the above query. Result: ", "{narrative}"),
        ("For the topic of COVID-19 and the given query \"{title}\", describe the type of document that is relevant. Result: ", "{narrative}"),
        ("What is the intented document related to the query titled \"{title}\"? Answer: ", "{narrative}"),
        ("Here is a query:\n\n{title}\n\nPlease indicate which kind of document is relevant. Result: ", "{narrative}"),
        ("{title}\n\nPlease describe relevant documents for the above topic in terms of covid. Result: ", "{narrative}"),
        ("Please describe some medical documents about the topic \"{title}\". Result: ", "{narrative}"),
        ("Please indicate some documents related to COVID-19 for the topic \"{title}\". Result: ", "{narrative}"),
        ("Provide the purpose or intent behind the query titled [{title}]. Answer: ", "{narrative}"),
        ("Which document has strong relevance to the covid topic \"{title}\"? Answer: ", "{narrative}"),
        ("What kind of document does the topic \"{title}\" want to find? Answer: ", "{narrative}"),
        ("Seeking for document about COVID-19\n\n{narrative}\n\nHow to construct a query? Query: ", "{title}"),
        ("{narrative}\n\nI'm looking for documents like this about COVID-19. Please provide me with a query. Query: ", "{title}")
    ],
    "query-description-fire": [
        ("{title}\n\nWhich document is related to the above query? Answer: ", "{narrative}"),
        ("For the query \"{title}\", please indicate some documents that may be related to it. Result: ", "{narrative}"),
        ("What is the subject matter of the query \"{title}\"? Answer: ", "{narrative}"),
        ("Please descibe relevant documents about the query {title}. Result: ", "{narrative}"),
        ("{title}\n\nWhat is the information sought in the above query? Answer: ", "{narrative}"),
        ("Here is a query \"{title}\". Please indicate what kinds of documents are relevant. Answer: ", "{narrative}"),
        ("Query: {title}\n\nWhat are the relevant documents? Answer: ", "{narrative}"),
        ("Describe documents relevant to the query \"{title}\". Result: ", "{narrative}"),
        ("This ia a query \"{title}\". Analyze its search intent and indicate which kind of document is relevant. Result: ", "{narrative}"),
        ("Read the following query:\n\n{title}\n\nIndicate some relevant documents. Result: ", "{narrative}"),
        ("I need assistance in finding some documents:\n\n{narrative}\n\nPlease suggest a search query for me. Query: ", "{title}"),
        ("Looking for articles:\n\n{narrative}\n\nPlease give me a query. Query: ", "{title}")
    ],
    "query-expansion-gov2": [
        ("{title}\n\nWhat is this query asking? Answer: ", "{description}"),
        ("Expand this query so that the retrieval performance can be enhanced:\n\n{title}\n\nExpanded query: ", "{description}"),
        ("Based on this query: {title}, write a more detailed one. Answer: ", "{description}"),
        ("Query Expansion:\n\n{title}\n\nAnswer: ", "{description}"),
        ("Make this query more specific:\n\n{title}\n\nResult: ", "{description}"),
        ("{title}\n\nRewrite the above query to improve search performance. Result: ", "{description}"),
        ("Could you please help me expand this query so that its intent is more clear?\n\n{title}\n\nResult: ", "{description}"),
        ("Try to extend this question to be more specific: {title}. Result: ", "{description}"),
        ("Here is a question: {title} Can you expand it for searching? Answer: ", "{description}"),
        ("This ia a query issued to search engine: {title}\nRewrite to describe its intent. Result: ", "{description}"),
        ("{description}\n\nBased on this intent description, you need to suggest a query. Query: ", "{title}"),
        ("The expanded version of query is\n\n{description}\n\nCondense it to a simple query. Query: ", "{title}")
    ],
    "query-expansion-trec-robust": [
        ("Given the following query, rewrite it to refine search.\n\n{title}\n\nResult: ", "{description}"),
        ("Enhance the following question for better retrieval results:\n\n{title}\n\nEnhanced query: ", "{description}"),
        ("You're presented with this initial query: {title}\nHow can you make it more targeted? Answer: ", "{description}"),
        ("Refine this query:\n{title}\nResult: ", "{description}"),
        ("Transform this broad query into a more precise one:\n\n{title}\n\nResult: ", "{description}"),
        ("Read this query: {title}\nDescribe its underlying aim. Result: ", "{description}"),
        ("Could you provide a more detailed version of this question?\n\n{title}\n\nExpanded query: ", "{description}"),
        ("Refine this search query to better capture the user's intent:\n\n{title}\n\nResult: ", "{description}"),
        ("Question:\n{title}\nExpanded Question: ", "{description}"),
        ("Analyze the following query:\n{title}\nRewrite it so that relevant documents are easier to find. Result: ", "{description}"),
        ("Simplify the expanded query:\n\n{description}\n\ninto a single question. Query: ", "{title}"),
        ("Formulate a brief question from the description:\n\n{description}\n\nResult: ", "{title}")
    ],
    "query-expansion-trec-covid": [
        ("Question: \"{title}\" Give me a more comprehensive description based on it. Result: ", "{description}"),
        ("Take this query:\n\n{title}\n\nHow can we make it more context-specific? Answer: ", "{description}"),
        ("Help improve this search request:\n\n{title}\n\nNew request: ", "{description}"),
        ("This is a user query:\n{title}\nExpand it with more details. Result: ", "{description}"),
        ("Here is a question\n{title}\nWhat aspects of its topic can be emphasized to improve search? Answer: ", "{description}"),
        ("Convert this query into a more detailed one: {title}. Result: ", "{description}"),
        ("Read this query:\n{title}\nEnhance it with more context that is useful for searching. Result: ", "{description}"),
        ("{title}\nAdd some information to the above question. Result: ", "{description}"),
        ("You are a query rewriter, you should transform the given query into a more targeted one so that the information need can be better addressed.\n\nQuery:\n{title}\nRewrite: ", "{description}"),
        ("How to expand this question towards higher retrieval quality?\n{title}\nResult: ", "{description}"),
        ("Take the comprehensive information and create a succinct question:\n{description}\nQuestion: ", "{title}"),
        ("Generate a concise query from the extensive description:\n{description}\nQuery: ", "{title}")
    ],
    "query-expansion-fire": [
        ("Based on the question:\n\n{title}\n\nprovide additional details to make it more informative. Result: ", "{description}"),
        ("This is a search request: {title}. Enrich it with relevant context. Result: ", "{description}"),
        ("Improve this user query:\n{title}\nEnhance it to yield more accurate search results. Result: ", "{description}"),
        ("Expand this query:\n{title}. Result: ", "{description}"),
        ("Transform this query into a more precise one: {title}. Result: ", "{description}"),
        ("Examine this search query:\n{title}\nAdd relevant information to refine its scope for better results. Result: ", "{description}"),
        ("{title}\nInclude additional context to better focus on the preceding question. Result: ", "{description}"),
        ("As a query enhancer, your goal is to make this query more effective when searching. Expand the query:\n{title}\nResult: ", "{description}"),
        ("How can we expand the question and enhance the search capabilities?\n{title}\nAnswer: ", "{description}"),
        ("Query: \"{title}\" Please add more relevant information to it to capture user's information need. Result: ", "{description}"),
        ("The verbose version of a query is\n\n{description}\n\nGive me a concise one. Query: ", "{title}"),
        ("{description}\nNow simplify it to a query. Query: ", "{title}")
    ],
    "query-expansion-query2doc": [
        ("Write a passage that can answer the given query:\n{query}\nPassage: ", "{pseudo_doc}"),
        ("What is the expansion of this query:\n\n{query}\n\nExpansion: ", "{pseudo_doc}"),
        ("Query:\n\n{query}\n\nRelevant Passage: ", "{pseudo_doc}"),
        ("Here is a query:\n{query}\nGenerate a long-form expansion for it. Expansion: ", "{pseudo_doc}"),
        ("Provide a background document to answer the given question.\n\n{query}\n\nDocument: ", "{pseudo_doc}"),
        ("\"{query}\" Expand this query. Result: ", "{pseudo_doc}"),
        ("Address the following query with a detailed explanation:\n{query}\nResult: ", "{pseudo_doc}"),
        ("Query: {query} Expansion: ", "{pseudo_doc}"),
        ("Generate a detailed narrative in response to the query:\n{query}\nNarrative: ", "{pseudo_doc}"),
        ("Please give me a passage to answer the query '{query}'. Passage: ", "{pseudo_doc}"),
        ("{pseudo_doc}\nWhat question is it raising? Question: ", "{query}"),
        ("The expansion is\n{pseudo_doc}\nNow condense it to a query. Query: ", "{query}")
    ],
    "query-expansion-trec-cast": [
        ("Here is a query: \"{title}\" Write a description about the user's information need. Desription: ", "{description}"),
        ("Help add more details for the query:\n{title}\nResult: ", "{description}"),
        ("What is the user's specific search intent when issuing this query:\n{title}\nIntent: ", "{description}"),
        ("Query:\n\n{title}\n\nFull description of the information need. Description: ", "{description}"),
        ("Interpret the user's query:\n{title}\nWhat is the underlying purpose of this search request? Answer: ", "{description}"),
        ("Based on the following query, infer what problem the user may meet.\n\n{title}\n\nResult: ", "{description}"),
        ("What is the user trying to search by this query:\n{title}\nAnswer: ", "{description}"),
        ("Provide a more precise and comprehensive scope for the user's search:\n{title}\nResult: ", "{description}"),
        ("Elaborate on the user's query:\n{title}\nResult: ", "{description}"),
        ("Unpack the user's search intent in the following query:\n{title}\nWhat specific solution are they seeking? Answer: ", "{description}"),      
        ("Here is the information need\n{description}\nSimply summarize it to a query. Query: ", "{title}"),
        ("The detailed version is\n{description}\nWhat is the corresponding query? Answer: ", "{title}")   
    ],
    "query-expansion-trec-web": [
        ("Expand the query with more context\n{title}\nResult: ", "{description}"),
        ("Here is a search query:\n\n{title}\n\nWhat does the user trying to find? Answer: ", "{description}"),
        ("Question:\n{title}\nHow can we expand this query to make it more targeted? Answer: ", "{description}"),
        ("Dissect the user's query:\n{title}\nResult: ", "{description}"),
        ("Provide additional information to refine the search query:\n{title}\nResult: ", "{description}"),
        ("Interpret the user's intention with this query:\n{title}\nResult: ", "{description}"),
        ("With this initial query, how can we make it more precise and actionable?\n{title}\nAnswer: ", "{description}"),
        ("Assume a user has this query in mind:\n\n{title}\n\nHow can we make it more informative or detailed? Answer: ", "{description}"),
        ("Given the query {title}, try to inject more information into it so that the user can fulfill their need. Result: ", "{description}"),
        ("{title}\n\nThe above query may be ambiguous. Please write more context for it. Result: ", "{description}"),
        ("{description}\nIt describes the information the user want to find. Put it simply as a query. Query: ", "{title}"),
        ("Given the detailed description below, generate a query.\n{description}\nQuery: ", "{title}")
    ],
    "query-reformulation-codec":[
        ("A question in the area of \"{domain}\" is \"{title}\".\nWe know \"{guidelines}\".\nPlease reform the question. Reformulations: ", "{reformulations}"),
        ("Consider the topic of \"{domain}\" with the question \"{title}\". Given the background information \"{guidelines}\", how can we reformulate the question? Answer: ", "{reformulations}"),
        ("In the field of \"{domain}\", the question \"{title}\" has been raised. Given the guidelines \"{guidelines}\", can you rephrase the question? Answer: ", "{reformulations}"),
        ("The question \"{title}\" is related to \"{domain}\". With the information \"{guidelines}\", how could we restate the question? Answer: ", "{reformulations}"),
        ("Given the domain \"{domain}\", the question \"{title}\" arises. Considering the guidelines \"{guidelines}\", please rewrite the question. Rewrite: ", "{reformulations}"),
        ("The question is \"{title}\". How can we restructure the question? Answer: ", "{reformulations}"),
        ("In the context of \"{domain}\", the question \"{title}\" is posed. Given the guidelines \"{guidelines}\", can you rephrase the question differently? Answer: ", "{reformulations}"),
        ("The question \"{title}\" pertains to the domain \"{domain}\". How can we reword the question in a different way? Answer: ", "{reformulations}"),
        ("In the \"{domain}\" domain, the question \"{title}\" is asked. Considering the guidelines \"{guidelines}\", reformulate the question. Reformulations: ", "{reformulations}"),
        ("The query \"{title}\" is in the \"{domain}\" domain. How can we rephrase the query in another way? Answer: ", "{reformulations}"),
        ("Given the domain, question, and the guidelines. Reword the question differently.\n\nDomain:\"{domain}\"\n\nQuestion:\"{title}\"\n\nGuidelines:\"{guidelines}\"\n\nAnswer: ", "{reformulations}"),
        ("The question is \"{title}\". How can we rewrite the question in a new way? Answer: ", "{reformulations}")
    ],
    "query-reformulation-qrecc":[
        ("Given a search context \"{context}\". Reformulate the query \"{title}\". Reformulation: ", "{reformulations}"),
        ("Context: {context}\n\nQuery: {title}\n\nRewrite the query based on the context in a different way. Result: ", "{reformulations}"),
        ("In a conversational question answering system, the question \"{title}\" is asked. The previous context is \"{context}\". How can we rephrase the query? Answer: ", "{reformulations}"),
        ("In a conversation, the context is \"{context}\", and the currrent question is \"{title}\". How can we reword the inquiry? Answer: ", "{reformulations}"),
        ("In a dialogue, the context is \"{context}\", and the current question is \"{title}\". How might we rewrite the question? Answer: ", "{reformulations}"),
        ("During a conversation, the question is \"{title}\". The conversation context is \"{context}\". Rewrite the question. Reformulation: ", "{reformulations}"),
        ("Given the dialogue history \"{context}\". The current query is \"{title}\". How can we rewrite the query? Answer: ", "{reformulations}"),
        ("The question \"{title}\" was proposed after the context \"{context}\". How can we reformulate the question? Answer: ", "{reformulations}"),
        ("Based on the dialogue context:\n\n{context}\n\nRewrite the following question:\n\n{title}\n\nResult: ", "{reformulations}"),
        ("Given the question\n\n{title}\n\nPlease rewrite it according to the context\n\n{context}\n\nto make it more clear. Rewrite: ", "{reformulations}"),
        ("In a dialogue session, the previous dialogue context is\n\n{context}\n\nNow, the current question is\n\n{title}\n\nHow to reformulate it to make it more clear? Answer: ", "{reformulations}"),
        ("Here is a dialogue context:\n\n{context}\n\nNow, a new question is proposed:\n\n{title}\n\nCan you reformulate it to be more clear? Answer: ", "{reformulations}")
    ],
    "query-reformulation-canard":[
        ("Search context: {context}\nHistory: \"{history}\"\nQuery: \"{title}\"\nRewrite the query in a different way. Rewrite: ", "{reformulations}"),
        ("In a session \"{history}\", the query \"{title}\" is asked . How can we rephrase the query? Answer: ", "{reformulations}"),
        ("Someone asked a question \"{title}\" in a conversation \"{history}\". How might we rewrite the question? Answer: ", "{reformulations}"),
        ("Please rewrite the qustion \"{title}\" based on the context \"{context}\" and search history \"{history}\". Rewrite: ", "{reformulations}"),
        ("\"{history}\"\n\nBased on the context above, how can we rephrase the question \"{title}\"? Answer: ", "{reformulations}"),
        ("In the context of \"{history}\", how can we reformulate the question \"{title}\"? Answer: ", "{reformulations}"),
        ("Given the search context {context} and history \"{history}\", how might we rewrite the query \"{title}\"? Answer: ", "{reformulations}"),
        ("In the scenario \"{history}\", how can we rephrase the question \"{title}\"? Answer: ", "{reformulations}"),
        ("Considering the search context {context} and conversation history \"{history}\", how might we reword the query \"{title}\"? Answer: ", "{reformulations}"),
        ("With the session context \"{history}\", how can we reformulate the query \"{title}\"? Answer: ", "{reformulations}"),
        ("Given the previous queries and system responses:\n\n{history}\n\nHow can we reformulate the current query \"{title}\"? Answer: ", "{reformulations}"),
        ("The search context is \"{history}\", how can we reformulate the new query \"{title}\"? Answer: ", "{reformulations}")
    ],
    "query-reformulation-cast19": [
        ("Session title: \"{title}\"\nSession description: \"{description}\"\nSession history: \"{history}\"\nQuery: \"{turn_title}\"\nRewrite the query in a different way. Rewrite: ", "{reformulations}"),
        ("The current query \"{turn_title}\" is about \"{description}\". The previous search queries include \"{history}\". How can we rephrase the current query? Answer: ", "{reformulations}"),
        ("Given the session title \"{title}\" and description \"{description}\", and the search context is \"{history}\", how can we rewrite the query \"{turn_title}\"? Answer: ", "{reformulations}"),
        ("In the session titled \"{title}\" with description \"{description}\", the previous search includes \"{history}\". How can we rephrase the query \"{turn_title}\"? Answer: ", "{reformulations}"),
        ("Considering the session title \"{title}\" and description \"{description}\", if the search context is \"{history}\", how might we reword the query \"{turn_title}\"? Answer: ", "{reformulations}"),
        ("Given the session \"{title}\" described as \"{description}\", there are some search contexts include \"{history}\", how can we reformulate the query \"{turn_title}\"? Answer: ", "{reformulations}"),
        ("In the session \"{title}\" described as \"{description}\", the previous search is \"{history}\". How might we rewrite the query \"{turn_title}\"? Answer: ", "{reformulations}"),
        ("Considering the session about \"{title}\", the search context is \"{history}\". Can you rephrase the query \"{turn_title}\"? Answer: ", "{reformulations}"),
        ("Given the session with the topic of \"{title}\", the user's previous interactions with the search engine incldue \"{history}\". Please reformulate the query \"{turn_title}\". Reformulation: ", "{reformulations}"),
        ("In the session titled \"{title}\", it is about \"{description}\". The previous search queries are \"{history}\". Reformulate the query \"{turn_title}\". Reformulation: ", "{reformulations}"),
        ("Search context:\n\n{history}\n\nReformulate the current query:\n\n{turn_title}. Reformulation: ", "{reformulations}"),
        ("The search is about \"{title}\". The previous queries include \"{history}\". Now reformulate the query \"{turn_title}\". Reformulation: ", "{reformulations}")
    ],
    "query-reformulation-cast2x": [
        ("Session history: \"{history}\"\nQuery: \"{turn_title}\"\nRewrite the query in a different way. Rewrite: ", "{reformulations}"),
        ("The previous queries are \"{history}\". The current query is \"{turn_title}\". How can we rephrase it? Answer: ", "{reformulations}"),
        ("Given the search context as \"{history}\", how can we rewrite the current query \"{turn_title}\"? Answer: ", "{reformulations}"),
        ("In a session, the previous search queries include \"{history}\". How can we rephrase the query \"{turn_title}\"? Answer: ", "{reformulations}"),
        ("Considering the search context as \"{history}\", how might we reword the query \"{turn_title}\"? Answer: ", "{reformulations}"),
        ("Given the search session \"{history}\", how can we reformulate the query \"{turn_title}\"? Answer: ", "{reformulations}"),
        ("In the session with previous queries of \"{history}\". How might we rewrite the query \"{turn_title}\"? Answer: ", "{reformulations}"),
        ("Considering the session where the search context is \"{history}\". Can you rephrase the query \"{turn_title}\"? Answer: ", "{reformulations}"),
        ("Given a session, the user's previous interactions with search engines incldue \"{history}\". Please reformulate the query \"{turn_title}\". Reformulation: ", "{reformulations}"),
        ("Reformulate the query \"{turn_title}\" based on the previous queries \"{history}\". Reformulation: ", "{reformulations}"),
        ("Search history:\n\n{history}\n\nReformulate the current query: {turn_title} Answer: ", "{reformulations}"),
        ("Given the following queries\n\n{history}\n\nPlease reformulate the new query: {turn_title} Result: ", "{reformulations}")
    ],
    "query-reformulation-gecor": [
        ("\"{title}\"\nRewrite it based on the context:\n\n{context}\n\nRewrite: ", "{reformulations}"),
        ("Goal: \"{goal}\"\n\nContext: \"{context}\"\n\nQuery: \"{title}\"\n\nPlease rewrite the query in a different way. Rewrite: ", "{reformulations}"),
        ("The dialogue context is \"{context}\". The user input is \"{title}\". How can we rephrase the user input? Answer: ", "{reformulations}"),
        ("Reformulate the user input \"{title}\" given the goal \"{goal}\" and the context \"{context}\". Reformulation: ", "{reformulations}"),
        ("In a dialogue with the goal \"{goal}\" and context \"{context}\", how might we rephrase the user input \"{title}\"? Answer: ", "{reformulations}"),
        ("Considering the dialogue goal \"{goal}\" and context \"{context}\", how can we reformulate the user input \"{title}\"? Answer: ", "{reformulations}"),
        ("Given the dialogue context \"{context}\", how can we rewrite the user input \"{title}\"? Answer: ", "{reformulations}"),
        ("Given the dialogue's goal \"{goal}\" and context \"{context}\", how can we rephrase the user's input \"{title}\"? Answer: ", "{reformulations}"),
        ("In a conversation with the aim of \"{goal}\" and context of \"{context}\", how might we reformulate the user's query \"{title}\"? Answer: ", "{reformulations}"),
        ("Considering the goal \"{goal}\" and context \"{context}\" of the dialogue, how can we rewrite the user's query \"{title}\"? Answer: ", "{reformulations}"),
        ("Given the dialogue context as \"{context}\", the current user input is \"{title}\". Please help reformulate it to be more clear. Reformulation: ", "{reformulations}"),
        ("For a dialogue context \"{context}\", how can we rewrite the user's current input \"{title}\"? Answer: ", "{reformulations}")
    ],
    "query-clarification-mimics": [
        ("Query: \"{query}\". Clarify the query. Clarification: ", "{clarification}"),
        ("Query: {query}\n\nClarification: ", "{clarification}"),
        ("Make some clarifications for the query \"{query}\". Clarification: ", "{clarification}"),
        ("Query: \"{query}\"\nWhat are the possible clarifications? Answer: ", "{clarification}"),
        ("User input: \"{query}\". Please ask a clarification question. Clarification: ", "{clarification}"),
        ("{query}\nCan you clarify the above query? Answer: ", "{clarification}"),
        ("Considering the query \"{query}\", what clarification options would you suggest? Answer: ", "{clarification}"),
        ("{query}\n\nWhat clarification options can be suggested? Answer: ", "{clarification}"),
        ("Identify some clarification queries for the query \"{query}\". Clarification: ", "{clarification}"),
        ("If the query is \"{query}\", can you ask some clarification questions? Answer: ", "{clarification}"),
        ("Clarify the following query: \"{query}\" Clarification: ", "{clarification}"),
        ("Provide some clarifications for the given query \"{query}\" Clarification: ", "{clarification}")
    ],
    "query-clarification-mimics-duo": [
        ("Query:\n\n{query}\n\nClarify the query to refine the search. Clarification: ", "{clarification}"),
        ("Query: {query}\nClarification: ", "{clarification}"),
        ("Make some clarifications for the query \"{query}\" Clarification: ", "{clarification}"),
        ("Query: \"{query}\"\nWhat are the possible clarifications? Answer: ", "{clarification}"),
        ("User input: \"{query}\". Please provide me with some clarification questions. Clarification: ", "{clarification}"),
        ("{query}\n\nCan you clarify this query? Answer: ", "{clarification}"),
        ("Considering the query \"{query}\", what clarification questions would you ask? Answer: ", "{clarification}"),
        ("\"{query}\"\n\nWhat clarification question can be asked? Answer: ", "{clarification}"),
        ("Identify some possible clarifications for the query \"{query}\". Clarification: ", "{clarification}"),
        ("If the query is \"{query}\", how would you clarifiy it? Answer: ", "{clarification}"),
        ("If a user input a query \"{query}\", how to clarify it and understand her/his search intent? Answer: ", "{clarification}"),
        ("When the \"{query}\" is given, what are possible clarifications? Answer: ", "{clarification}")
    ],
    "query-clarification-clariq-fkw": [
        ("Query: {title} Clarification: ", "{clarification}"),
        ("Query: \"{title}\"\nPlease try to ask me a clarification question. Question: ", "{clarification}"),
        ("The query is \"{title}\". Ask a clarification question for it. Question: ", "{clarification}"),
        ("If you are asked with the query \"{title}\", how do you need to clarify? Answer: ", "{clarification}"),
        ("Query: {title}\n\nIf you want to understand the previous query, what clarification questions will you ask? Answer: ", "{clarification}"),
        ("If I want to understand the user query \"{title}\", what clarification questions do I need? Answer: ", "{clarification}"),
        ("Can you ask a clarification question about \"{title}\"? Answer: ", "{clarification}"),
        ("\"{title}\" - how to ask a clarification question? Answer: ", "{clarification}"),
        ("I have a query \"{title}\". If you are a search engine, how will you clarify this query? Answer: ", "{clarification}"),
        ("The query is \"{title}\". If you are required to provide me with some relevant documents, what questions will you ask? Answer: ", "{clarification}"),
        ("Ask a clarification question for the query \"{title}\" Question: ", "{clarification}"),
        ("Given a query \"{title}\", provide me with a clarification question. Question: ", "{clarification}"),
    ],
    "query-clarification-raocq": [
        ("Query: {title}. {description}, ask a clarification querstion. Result: ", "{clarification}"),
        ("Here are some descriptions \"{description}\" about \"{title}\", if you want to answer the question, what do you need to clarify? Answer: ", "{clarification}"),
        ("The problem is {title}. The descrption is {description}. Can you ask a clarification question to help understand the problem? Answer: ", "{clarification}"),
        ("Given a problem {title} and its description {description}. You need to ask a relevant clarification question to help deal with the problem. Question: ", "{clarification}"),
        ("Title:\n\n{title}\n\nDescription:\n\n{description}\n\nAsk a clarification question for the problem. Question: ", "{clarification}"),
        ("If you want to solve a problem \"{description}\" about {title}, what do you need to clarify? Answer: ", "{clarification}"),
        ("I'm faced with a problem {description} about {title}. You need to provide me with some suggestions. What do you need to know? Answer: ", "{clarification}"),
        ("{title}. {description} Can you help me to solve it? Answer: ", "{clarification}"),
        ("I meet a problem about {title}. {description}. How can I solve it? Answer: ", "{clarification}"),
        ("Can you help me solve this problem?\n\n{title}\n\nDescription: {description}\n\nQuestion: ", "{clarification}"),
        ("I have a problem about {title}. More detailed description is: {description}. You need to help me with my problem, and what information do you need to know? Result: ", "{clarification}"),
        ("Question: {title}\n\nDescription: {description}\n\nPlease help me to solve it. Is there any question you want to know? Question: ", "{clarification}")
    ],
    "query-subtopic-generation-trec-web": [
        ("Query: {title}\nGenerate some subtopics. Subtopics: ", "{subtopic_title}"),
        ("Given the query \"{title}\" and its description \"{description}\", please generate its subtopics. The subtopics should be relevant to the query but describe different aspects. Subtopics: ", "{subtopic_title}"),
        ("The query is \"{title}\". Generate its subtopics: ", "{subtopic_title}"),
        ("Query\n\n{title}\n\nIts subtopics can be: ", "{subtopic_title}"),
        ("Here is a query \"{title}\". Its description is \"{description}\". Please provide some subtopics about the query. Subtopics: ", "{subtopic_title}"),
        ("Here are some descriptions about the query \"{title}\": {description} Generate the query's subtopics. Subtopics: ", "{subtopic_title}"),
        ("Please generate some subtopics about the query: {title} Subtopics: ", "{subtopic_title}"),
        ("Can you provide some subtopics in terms of the query {title}? Answer: ", "{subtopic_title}"),
        ("If the query is {title}, can you porvide some subtopics? Answer: ", "{subtopic_title}"),
        ("I have a query {title} Please provide me with some subtopics. Subtopics: ", "{subtopic_title}"),
        ("Generate some possible subtopics for the query {title} Subtopics: ", "{subtopic_title}"),
        ("Please provide me with some possible subtopics about {title} Subtopics: ", "{subtopic_title}")
    ],
    "query-matching-msrp": [
        ("Here are two sentences:\n{sentence1}\n{sentence2}\nDo they have the same meaning?\n- yes\n- no\nAnswer: ", "{answer}"),
        ("Here are two sentences:\n\n{sentence1}\n\n{sentence2}\nAre the two sentences saying the same thing?\nAnswer: ", "{answer}"),
        ("{sentence1}\n\n{sentence2}\n\nDo the above sentences mean the same thing? Answer: ", "{answer}"),
        ("{sentence1}\n\n{sentence2}\n\nPlease tell me if the sentences above mean the same.\n\nOptions:\n-yes \n-no\nAnswer: ", "{answer}"),
        ("{sentence1}\n{sentence2}\nAre these sentences conveying the same meaning? Answer: ", "{answer}"),
        ("{sentence1}\n{sentence2}\nIf the first sentence is true, is the second one also true? Answer: ", "{answer}"),
        ("{sentence1}\n{sentence2}\nAre these two sentences paraphrases of each other? Options: - yes - no Answer: ", "{answer}"),
        ("Do the following two sentences have the same meaning?\n{sentence1}\n{sentence2}\nAnswer: ", "{answer}"),
        ("Do these two sentences mean the same thing?\n{sentence1}\n{sentence2}\nAnswer: ", "{answer}"),
        ("Do these sentences have the same meaning?\n{sentence1}\n{sentence2}\nAnswer: ", "{answer}"),
        ("Judge whether the following two sentences have the same meaning:\n\n1. {sentence1}\n\n2. {sentence2}\n\nResult: ", "{answer}"),
        ("Please check whether the two sentences have the same meaning.\n\n{sentence1}\n\n{sentence2}\n\nResult: ", "{answer}")
    ],
    "qury-suggestion-aol": [
        ("Search context:\n{context}\nInfer the next query: ", "{target_query}"),
        ("Given the search context as follows:\n{context}\nPlease suggest the next query. Suggestion: ", "{target_query}"),
        ("The search context is presented below:\n{context}\nCan you predict the next query? Answer: ", "{target_query}"),
        ("Generate the next query based on the prevous queries \"{history_queries}\". Next query: ", "{target_query}"),
        ("In a search session, the previous queries include \"{history_queries}\", and their corresponding clicked documents are \"{history_docs}\". Generate the next query. Next query: ", "{target_query}"),
        ("{context}\n\nAccording to the above search session information, predict the next query: ", "{target_query}"),
        ("The user's search session is as follows:\n{context}\nWhat is the possible next query? Answer: ", "{target_query}"),
        ("Given a search session as:\n{context}\nYou need to suggest the next query. Result: ", "{target_query}"),
        ("My previous search context is:\n{context}\nPlease suggest me the next query. Result: ", "{target_query}"),
        ("Predict the next query based on the previous queries: {history_queries} Next query: ", "{target_query}"),
        ("Infer the next query based on the previous ones: {history_queries} Next query: ", "{target_query}"),
        ("Here are some queries: \"{history_queries}\" Can you infer the next one? Answer: ", "{target_query}")
    ],
    "query-intent-classification-orcas-i": [
        ("Query: \"{title}\"\nWhat is the type of the query?\n\nOptions:\n- factual\n- abstain\n- instrumental\n- transactional\n- navigational\nAnswer: ", "{query_type}"),
        ("What is the intent type of the query \"{title}\"? Please select from {factual, abstain, instrumental, transactional, navigational} Answer: ", "{query_type}"),
        ("\"{title}\"\nWhat type of query is it? OPTIONS:\nA. factual\nB. abstain\nC. instrumental\nD. transactional\nE. navigational\nAnswer: ", "{query_type}"),
        ("\"{title}\"\nWhat is the intent type of the query? Select one from the following options:\n(A) factual\n(B) abstain\n(C) instrumental\n(D) transactional\n(E) navigational\nAnswer: ", "{query_type}"),
        ("Given the question \"{title}\", its intent label (factual, abstain, instrumental, transactional, or navigational) is: ", "{query_type}"),
        ("A user asked \"{title}\". What may be the type of the user's intent?\n\nOptions:\n- factual\n- abstain\n- instrumental\n- transactional\n- navigational\nAnswer: ", "{query_type}"),
        ("\"{title}\". Can you identify the query type? Options:\n[A] factual\n[B] abstain\n[C] instrumental\n[D] transactional\n[E] navigational\nAnswer: ", "{query_type}"),
        ("Considering the query \"{title}\", what might be the type of the user's intent? Options:\n- factual\n- abstain\n- instrumental\n- transactional\n- navigational\nAnswer: ", "{query_type}"),
        ("\"{title}\". What could be the possible type of intent of this query? Options:\n1. factual\n2. abstain\n3. instrumental\n4. transactional\n5. navigational\nAnswer: ", "{query_type}"),
        ("Identify the type of the query \"{title}\".\n\nOptions:\n- factual\n- abstain\n- instrumental\n- transactional\n- navigational\nAnswer: ", "{query_type}"),
        ("When looking at the query \"{title}\", what could be the user's intention? Options:\n- informative\n- undecided\n- functional\n- transactional\n- directional\nAnswer: ", "{query_type}"),
        ("What is the purpose of the query \"{title}\"? Please select one of the following:\nI. informative\nII. undecided\nIII. functional\nIV. transactional\nV. directional\nAnswer: ", "{query_type}"),
    ],
    "query-intent-classification-mantis": [
        ("In a session about \"{title}\". User asked \"{turn_title}\". What is the type of the question? Options: {original question, further details, follow up question, information request, potential answer, positive feedback, negative feedback, greetings / gratitude, other} Answer: ", "{query_type}"),
        ("Given the session \"{title}\" and the question \"{turn_title}\", what is the query type? Options: original question, further details, follow up question, information request, potential answer, positive feedback, negative feedback, greetings / gratitude, other Answer: ", "{query_type}"),
        ("\"{turn_title}\" was asked in the session about \"{title}\". What is the query's type? You can select one or several types from the options {original question, further details, follow up question, information request, potential answer, positive feedback, negative feedback, greetings / gratitude, other} Answer: ", "{query_type}"),
        ("In the context of \"{title}\", the user asked \"{turn_title}\". What is the query type? Select suitable labels from {original question, further details, follow up question, information request, potential answer, positive feedback, negative feedback, greetings / gratitude, other} Answer: ", "{query_type}"),
        ("The user asked \"{turn_title}\" in a session about \"{title}\". What is the type of user intent? Options:\nA. further details\nB. follow up question\nC. information request\nD. potential answer\nE. positive feedback\nF. negative feedback\nG. greetings / gratitude\nH. other\nI. original question\nAnswer: ", "{query_type}"),
        ("\"{turn_title}\". In the context of \"{context}\", what is the query type? Options:\nA. further details\nB. follow up question\nC. information request\nD. potential answer\nE. positive feedback\nF. negative feedback\nG. greetings / gratitude\nH. other\nI. original question\nAnswer: ", "{query_type}"),
        ("Considering the session \"{title}\" and the context \"{context}\", the user asked \"{turn_title}\". Select the question type from {further details, follow up question, original question, information request, potential answer, positive feedback, negative feedback, greetings / gratitude, other} Answer: ", "{query_type}"),
        ("\"{turn_title}\" was asked during the \"{title}\" session. The session context is \"{context}\". What is the query type? Options: A. further details B. follow up question C. information request D. potential answer E. positive feedback F. original question G. negative feedback H. greetings / gratitude I. other Answer: ", "{query_type}"),
        ("Identify the intent of the question \"{turn_title}\" in the session \"{title}\" with the context of \"{context}\". Options:\n- further details\n- follow up question\n- information request\n- potential answer\n- original question\n- positive feedback\n- negative feedback\n- greetings / gratitude\n- other\nAnswer: ", "{query_type}"),
        ("\"{turn_title}\".\n In the session about \"{title}\", given the context as \"{context}\", what is the intent type of this question?\nOptions:\n\n- further details\n- follow up question\n- information request\n- potential answer\n- original question\n- positive feedback\n- negative feedback\n- greetings / gratitude\n- other\nAnswer: ", "{query_type}"),
        ("Within the session about \"{title}\", considering the context as \"{context}\", what is the intent type of this question \"{turn_title}\"?\nOptions:\n\n1. elaboration\n2. follow-up\n3. information request\n4. potential answer\n5. initial query\n6. positive feedback\n7. negative feedback\n8. greetings / gratitude\n9. other\nAnswer: ", "{query_type}"),
        ("Determine the intent of the question \"{turn_title}\" in the session \"{title}\". Options:\n- elaboration\n- follow-up\n- information request\n- potential answer\n- initial query\n- positive feedback\n- negative feedback\n- greetings / gratitude\n- other\nAnswer: ", "{query_type}"),
    ],
    "query-intent-classification-trec-web": [
        ("Query: \"{title}\"\nQuery description: \"{description}\"\nWhat is the type of the query (faceted or ambiguous)? Answer: ", "{query_type}"),
        ("Given the query \"{title}\" and its description \"{descrisption}\", what is the query type? Options: - faceted - ambiguous Answer: ", "{query_type}"),
        ("The query is: \"{title}\", its description is \"{description}\". Is it a faceted query or an ambiguous query? Answer: ", "{query_type}"),
        ("In terms of the query {title} and its description \"{description}\", what is the type of the query? Options:\n- faceted\n- ambiguous\nAnswer: ", "{query_type}"),
        ("The user queried \"{title}\" with description \"{description}\". What is the type of the query? Options: (A) faceted (B) ambiguous Answer: ", "{query_type}"),
        ("Under a query \"{title}\" with description \"{description}\", a potential subtopic is \"{subtopic}\". What is the type of the subtopic (informational or navigational)? Answer: ", "{subtopic_type}"),
        ("Considering the query \"{title}\", Can you infer whether it is an ambiguous query or a faceted query? Answer: ", "{query_type}"),
        ("The query is {title}. Please identify its type (faceted or ambiguous): ", "{query_type}"),
        ("Identify the type of the query \"{title}\". Options: - faceted - ambiguous Answer: ", "{query_type}"),
        ("\"{title}\". what is the type of this query? Options:\n\n- faceted\n- ambiguous\nAnswer: ", "{query_type}"),
        ("Is the query \"{title}\" a faceted query or an ambiguous query? Answer: ", "{query_type}"),
        ("Please label the query with the type (faceted or ambiguous). \"{title}\" Label: ", "{query_type}")
    ],
    "fact-verification-fever": [
        ("Claim: \"{claim}\"\nEvidence: \"{evidences}\"\nPlease label whether the claim is supported or refuted by the evidence. Options: - support - refute Label: ", "{claim_label}"),
        ("Given the claim \"{claim}\" and the evidence \"{evidences}\", please provide a label to indicate if the evidence supports or refutes the claim. Label: ", "{claim_label}"),
        ("Please provide a label (support or refute) for the claim \"{claim}\" based on the evidence \"{evidences}\". Result: ", "{claim_label}"),
        ("\"{claim}\"\nBased on the evidence \"{evidences}\", is the claim supported or refuted by the evidence? Answer: ", "{claim_label}"),
        ("Considering the claim \"{claim}\" and the evidence \"{evidences}\", does the evidences support or refute the claim? Answer: ", "{claim_label}"),
        ("\"{claim}\"\nGiven the evidence \"{evidences}\", does it support or refute the claim? Answer: ", "{claim_label}"),
        ("Please assign a label to the claim \"{claim}\" considering the evidence \"{evidences}\". Options: - support - refute. Choose the label that best reflects the relationship between the claim and the evidence. Label: ", "{claim_label}"),
        ("Claim: {claim}\n\nEvidence: {evidences}\n\nCheck whether the evidence supports or refutes the claim. Answer: ", "{claim_label}"),
        ("Label the relationship between the claim \"{claim}\" and the evidence \"{evidences}\". You can select a label from {support, refute}. Label: ", "{claim_label}"),
        ("\"{claim}\"\nBased on \"{evidences}\", which label {support or refute} can reflect their relationship? Answer: ", "{claim_label}"),
        ("Given the evidence \"{evidences}\", determine the appropriate label to describe its relationship with the claim \"{claim}\". The options are 'support' or 'refute'. Answer: ", "{claim_label}"),
        ("Does the evidence '{evidences}' support or refute the claim \"{claim}\"? Answer: ", "{claim_label}")
    ],
    "fact-verification-climate-fever": [
        ("Check the following claim \"{claim}\" and the corresponding evidences \"{evidences}\". Determine if the evidences 'support' or 'refute' the claim. If the claim is disputed, respond with 'disputed'. If the information is not enough, respond with 'not enough information'. Answer: ", "{claim_label}"),
        ("Claim: \"{claim}\"\n\nEvidence: \"{evidences}\"\n\nPlease label whether the evidences 'support' or 'refute' the claim. If the information is not enough, respond with 'not enough information'. If the claim is disputed, indicate this by responding with 'disputed'. Label: ", "{claim_label}"),
        ("Based on the given claim \"{claim}\" and the provided evidence \"{evidences}\", assign a label from the following options: 'support', 'refute', 'disputed', or 'not enough information'. This label should reflect whether the evidence supports or refutes the claim, if there is insufficient information to reach a conclusion, or if the claim itself is a matter of dispute. Label: ", "{claim_label}"),
        ("Can you label the claim \"{claim}\" based on the evidence \"{evidences}\"? Options:\n- support-\ndisputed\n- refute\n- not enough information\nChoose a label that best describes the relationship between the evidence and the claim: whether the evidence supports or refutes the claim, if the claim is disputed, or if there is not enough information for a definitive decision.\nAnswer: ", "{claim_label}"),
        ("Examine the relationship between the claim \"{claim}\" and the provided evidence \"{evidences}\". Select a label that best represents this relationship. Your options are: (A) support (B) refute (C) not enough information (D) disputed Answer: ", "{claim_label}"),
        ("Does the evidence \"{evidences}\" support or refute the claim \"{claim}\"? If the provided information is not enough to make a decision, respond with 'not enough information'. If the claim itself is disputed, respond with 'disputed'. Options: A. support B. refute C. not enough information D. disputed Answer: ", "{claim_label}"),
        ("Does the evidence \"{evidences}\" support or refute the claim \"{claim}\"? Is the claim disputed, or is there not enough information available to make a decision? Answer: ", "{claim_label}"),
        ("\"{claim}\"\n\nGiven the evidence \"{evidences}\", what is the appropriate label for the evidence? Options:\nA. support\nB. disputed\nC. refute\nD. not enough information\nSelect the option that best reflects whether the evidence supports or refutes the claim, whether there is sufficient information to make a decision, or if the claim itself is disputed.\nAnswer: ", "{claim_label}"),
        ("Examine the relationship between the claim \"{claim}\" and the evidence \"{evidences}\". Choose the option that best describes this relationship. Options:\n\n- support\n- refute\n- not enough information\n- disputed\nAnswer: ", "{claim_label}"),
        ("The claim is \"{claim}\". Based on the given evidence \"{evidences}\", assess whether it supports or refutes the claim. If the information is inadequate for a conclusive decision, select 'not enough information', and if the claim is inherently disputed, choose 'disputed'. Options:\n[A] support\n[B] refute\n[C] not enough information\n[D] disputed\nAnswer: ", "{claim_label}"),
        ("Please label the claim \"{claim}\" based on the provided evidence \"{evidences}\". Options:\n(I) support\n(II) refute\n(III) disputed\n(IV) not enough information\nChoose the label that accurately indicates if the evidence supports or refutes the claim, if there is adequate information to make a decision, or if the claim itself is a matter of dispute.\nAnswer: ", "{claim_label}"),
        ("I have a claim about the climate: \"{claim}\".\n\nHere are some evidences:\n\n{evidences}\n\nPlease label it. Options:\n1. support\n2. refute\n3. disputed\n4. not enough information\nSelect the label that accurately indicates whether the evidence supports or refutes the claim, whether there is sufficient information for a decision, or if the claim itself is a matter of dispute.\nAnswer: ", "{claim_label}")
    ],
    "fact-verification-scifact": [
        ("Claim: \"{claim}\"\n\nEvidence: \"{evidence}\"\n\nPlease label whether the evidence support or refute the claim. Label: ", "{evidence_label}"),
        ("Given the claim \"{claim}\" and the evidence \"{evidence}\", does the evidence support the claim? Please provide a label (support or refute). Label: ", "{evidence_label}"),
        ("Judge the relationship between the evidence \"{evidence}\" and the claim \"{claim}\" Options: - support - refute Answer: ", "{evidence_label}"),
        ("Based on the evidence \"{evidence}\", does it support or refute the claim \"{claim}\"? Options: A. support B. refute Answer: ", "{evidence_label}"),
        ("Claim: {claim}\nConsidering the evidence \"{evidence}\", does the evidence support the claim? Options: (A) support (B) refute Answer: ", "{evidence_label}"),
        ("Please label whether the claim \"{claim}\" is supported or refuted by the evidence \"{evidence}\"\n\n(A) support\n(B) refute\nAnswer: ", "{evidence_label}"),
        ("Here's a claim \"{claim}\" and some evidences \"{evidence}\". Does the evidence support or refute the claim? Answer: ","{evidence_label}"),
        ("According to the evidence \"{evidence}\", does it support or refute the claim \"{claim}\"? Answer: ", "{evidence_label}"),
        ("Label whether the claim \"{claim}\" is supported or refuted by the evidence \"{evidence}\". Options:\n\nA. support\nB. refute\nAnswer: ","{evidence_label}"),
        ("If \"{evidence}\" is true, does it support or refute the claim \"{claim}\"? Answer: ", "{evidence_label}"),
        ("{claim}\n\nGiven the evidence \"{evidence}\", does it support or refute the previous claim? Options:\n\nA. support\nB. refute\nAnswer: ", "{evidence_label}"),
        ("{evidence}\n\nDoes the evidence support or refute the claim \"{claim}\"? Options:\n\nA. support\nB. refute\nAnswer: ", "{evidence_label}")
    ],
    "summarization-xsum": [
        ("Summarize:\n\n{article}\n\nSummary: ", "{summary}"),
        ("Summarize this article:\n\n{article}\n\nSummary: ", "{summary}"),
        ("Summarize this article in your own words.\n\n{article}\n\nSummary: ", "{summary}"),
        ("{article}\nWhat is a summary of this text? Answer: ", "{summary}"),
        ("{article}\nWhat is this article about? Answer: ", "{summary}"),
        ("{article}\n\nThis article is about:", "{summary}"),
        ("Article: {article}\n\nA summary of the above article is? Answer: ", "{summary}"),
        ("Article: {article}\n\nSummarize the main points of that article. Summary: ", "{summary}"),
        ("Summarize this article in one sentence.\n\n{article}\n\nSummary: ", "{summary}"),
        ("{article}\n\nSummarize the article, please. Summary: ", "{summary}"),
        ("Write an article based on this summary:\n\n{summary}\n\nArticle: ", "{article}"),
        ("{summary}\n\nWrite an article based on the above summary. Article: ", "{article}"),
    ],
    "summarization-cnn-dm": [
        ("Write a summary for this article:\n\n{article}\n\nSummary: ", "{summary}"),
        ("{article}\n\nSummarize it\n\nSummary: ", "{summary}"),
        ("{article}\n\nGive me a summary. Summary: ", "{summary}"),
        ("{article}\n\nWhat are the important points of the article? Answer: ", "{summary}"),
        ("Generate the summary of:\n\n{article}\n\nSummary: ", "{summary}"),
        ("Here is an article:\n{article}\nWrite a short summary! Summary: ", "{summary}"),
        ("Article:\n{article}\nWhat are the main points in that article? Answer: ", "{summary}"),
        ("{article}\n\nBriefly summarize that article. Summary: ", "{summary}"),
        ("{article}\n\nWrite highlights for this article. Result: ", "{summary}"),
        ("{article}\n\nWhat are highlight points for this article? Answer: ", "{summary}"),
        ("Craft an article using the provided summary:\n\n{summary}\n\nArticle: ", "{article}"),
        ("Given the summary below, extend the content to form an article:\n\n{summary}\n\nArticle: ", "{article}"),
    ],
    "summarization-wikisum": [
        ("Generate a short summary for this article:\n\n{article}\n\nSummary: ", "{summary}"),
        ("Write a short summary for this text: {article} Summary: ", "{summary}"),
        ("Briefly summarize this wiki page: {article} Summary: ", "{summary}"),
        ("What is a shorter version of this:\n\n{article}\n\nSummary: ", "{summary}"),
        ("{article}\n\nWrite a brief summary in few sentences. Summary: ", "{summary}"),
        ("{article}\n\nWhat is a very short summary of the above text? Answer: ", "{summary}"),
        ("{article}\n\nSummarize the aforementioned text. Summary: ", "{summary}"),
        ("{article}\n\nCan you generate a short summary of the above paragraph? Answer: ", "{summary}"),
        ("Please summarize the wiki page:\n{article}\nSummary: ", "{summary}"),
        ("{article}\n\nWhat are the most important parts of this text? Answer: ", "{summary}"),
        ("Please expand the following text into a more detailed wiki page:\n{summary}\nArticle: ", "{article}"),
        ("Can you write a text in Wikipedia style based an the summary below?\n\n{summary}\n\nArticle: ", "{article}")
    ],
    "summarization-multi-news": [
        ("Summarize these articles:\n\n{article}\n\nSummary: ", "{summary}"),
        ("Write a summary based on these articles:\n\n{article}\n\nSummary: ", "{summary}"),
        ("Articles:\n\n{article}\nWhat is a summary? Answer: ", "{summary}"),
        ("{article}\n\nWhat is a one-paragraph summary of the above articles? Answer: ", "{summary}"),
        ("Here are some news article: {article}\n\nA summary of these is? Summary: ", "{summary}"),
        ("News articles:\n\n{article}\n\nWhat is a shorter version of the above articles?\n\nSummary: ", "{summary}"),
        ("{article}\n\nWrite a summary. Summary: ", "{summary}"),
        ("Articles:\n\n{article}\n\nSummary: ", "{summary}"),
        ("Given these articles:\n\n{article}\n\nCan you provide a brief summary? Answer: ", "{summary}"),
        ("These are the articles:\n\n{article}\n\nWhat would be a concise summary? Answer: ", "{summary}"),
        ("Please help me summarize these news articles\n\n{article}\n\nSummary: ", "{summary}"),
        ("{article}\n\nWhat is a summary of the above articles? Answer: ", "{summary}")
    ],
    "reading-comprehension-squad": [
        ("{title}:\n\n{context}\n\nPlease answer a question about this article. If the question is unanswerable, say \"unanswerable\". {question} Answer: ", "{answer}"),
        ("Read this and answer the question. If the question is unanswerable, say \"unanswerable\".\n\n{context}\n\n{question}\n\nAnswer: ", "{answer}"),
        ("What is a question about this article? If the question is unanswerable, say \"unanswerable\".\n\n{context}\n\n{question}\n\nAnswer: ", "{answer}"),
        ("{context}\n{question} (If the question is unanswerable, say \"unanswerable\") Answer: ", "{answer}"),
        ("{context}\nTry to answer this question if possible (otherwise reply \"unanswerable\"): {question} Answer: ", "{answer}"),
        ("{context}\nIf it is possible to answer this question, answer it for me (else, reply \"unanswerable\"): {question} Answer: ", "{answer}"),
        ("{context}\n\nAnswer this question, if possible (if impossible, reply \"unanswerable\"): {question} Answer: ", "{answer}"),
        ("Read this: {context}\n\n{question}\nWhat is the answer? (If it cannot be answered, return \"unanswerable\") Answer: ", "{answer}"),
        ("Read this: {context}\nNow answer this question, if there is an answer (If it cannot be answered, return \"unanswerable\"): {question} Answer: ", "{answer}"),
        ("{context}\nIs there an answer to this question (If it cannot be answered, say \"unanswerable\"): {question} Answer: ", "{answer}"),
        ("{context}\n\nPlease answer the question \"{question}\". If it cannot be answered, return unanswerable. Answer: ", "{answer}"),
        ("Article: {context}\n\nQuestion: {question}\n\nGive me the answer (if the question cannot be answered based on the article, just return unanswerable) Answer: ", "{answer}")
    ],
    "reading-comprehension-hotpot-qa": [
        ("Given the question: {question}, refer to the facts and generate your answer\n{supporting_facts}\nAnswer: ", "{answer}"),
        ("Considering the question: {question}, consult the facts below and answer it\n{supporting_facts}\nAnswer: ", "{answer}"),
        ("There are some facts\n{supporting_facts}\n\nBased on them, answer the question\n{question}\nAnswer: ", "{answer}"),
        ("Using the following details: {supporting_facts}\nExamine the question: {question}\nGenerate your response based on the facts. Response: ", "{answer}"),
        ("Refer to the supporting facts: {supporting_facts}\nGiven the question: {question}, provide your answer. Answer: ", "{answer}"),
        ("Question: {question}\nConsult the provided facts and generate your answer\n{supporting_facts}\nAnswer: ", "{answer}"),
        ("Given the question: {question}\nGenerate your answer based on the following facts\n{supporting_facts}\nAnswer: ", "{answer}"),
        ("Review the question: {question}\nAnswer it considering the provided facts\n{supporting_facts}\nAnswer: ", "{answer}"),
        ("Evaluate the question: {question}\nConsult the provided facts\n{supporting_facts}\nAnswer the question. Answer: ", "{answer}"),
        ("Review the supporting facts: {supporting_facts}\nExamine the question: {question}\nGenerate your response accordingly. Response: ", "{answer}"),
        ("Based on the following facts\n\n{supporting_facts}, answer the question: {question} Answer: ", "{answer}"),
        ("{supporting_facts}\n\nThe question is {question}. Please answer it. Answer: ", "{answer}"),
    ],
    "reading-comprehension-ms-marco": [
        ("Given a document\n{context}\n\nNow answer the question: {question} Answer: ", "{answer}"),
        ("Answer the question: {question}\n\nBased on an article\n\n{context}\nAnswer: ", "{answer}"),
        ("Question: {question}\nPlease read this article: {context}, then answer the question. Answer: ", "{answer}"),
        ("Read the passage: {context}\nThen answer the question: {question} Answer: ", "{answer}"),
        ("Question: {question}\nRead this article: {context}\nAnswer the question. Answer: ", "{answer}"),
        ("Given this question: {question}\n\nBased on these facts: {supporting_facts}\n\nAnd a related passage: {context}\n\nGenerate your answer. Answer: ", "{answer}"),
        ("Consider the passage: {context}\nThen answer the question {question} Answer: ", "{answer}"),
        ("Keep some facts in mind: {supporting_facts}\n\nThen answer the question: {question}\n\nBased on the context: {context}\n\nAnswer: ", "{answer}"),
        ("Question: {question}\n\nContext: {context}\n\nPlease answer the question. Answer: ", "{answer}"),
        ("There is a passage and some facts related to a question\n\n{context}\n\n{supporting_facts}\n\nNow answer it: {question} Answer: ", "{answer}"),
        ("Read the following context and answer the question: {question}\n\n{context}\n\nAnswer: ", "{answer}"),
        ("{context}\n\n{question}\n\nAnswer the previous question based on the given material. Answer: ", "{answer}"),
    ],
    "reading-comprehension-trivia-qa": [
        ("Answer the question: {question} Answer: ", "{answer}"),
        ("What is the answer of the question: {question} Answer: ", "{answer}"),
        ("Write the answer of: {question} Answer: ", "{answer}"),
        ("Question: \"{question}\", please answer. Answer: ", "{answer}"),
        ("{question} Answer: ", "{answer}"),
        ("{context}\n\nConsulting this, give your answer to: {question} Answer: ", "{answer}"),
        ("{question}\n\nAnswer this question referring to: {context} Answer: ", "{answer}"),
        ("Given the passage: {context}\nNow, provide the answer to the question: {question} Answer: ", "{answer}"),
        ("Consider the context: {context}\nNow, write the answer to the question: {question} Answer: ", "{answer}"),
        ("{context}\nAnswer the following question: {question} Answer: ", "{answer}"),
        ("Given the question: {question}\nPlease infer the answer. Answer: ", "{answer}"),
        ("{context}\n\n{question}\nWhat is the answer? Answer: ", "{answer}"),
    ],
    "reading-comprehension-bool-q": [
        ("{context}\nIs it true that {question}? Please answer in \"True\" or \"False\" Answer: ", "{answer}"),
        ("{context}\nFigure out if it is real or not: {question}\nOptions: \"True\" or \"False\" Answer: ", "{answer}"),
        ("Given an article: {context}\nDecide the genuineness: {question} Answer: ", "{answer}"),
        ("{context}\nIs the statement correct? (True/False)\n{question}\n Answer: ", "{answer}"),
        ("{question}\nIs the question supported by the text? {context} Answer: ", "{answer}"),
        ("{question}\nNow read the passage and examine if the answer is \"True\": {context} Answer: ", "{answer}"),
        ("{context}\nBased on this article, is it true that {question} Answer: ", "{answer}"),
        ("{context}\nCan we confirm the truthfulness of {question}? Please answer in \"True\" or \"False\" Answer: ", "{answer}"),
        ("{context}\nDetermine whether it is true or not: {question} Answer: ", "{answer}"),
        ("{question}\nIs it true given this: {context} Answer: ", "{answer}"),
        ("Is it true that {question} based on the following text?\n\n{context}\n\nAnswer: ", "{answer}"),
        ("{context}\n\n{question}? (True or False) Answer: ", "{answer}"),
    ],
    "reading-comprehension-webglm-qa": [
        ("Answer the question: {question}\nGiven references: {references}\nAnswer: ", "{answer}"),
        ("Question: {question}\nReferences: {references}\nNow answer the question based on the references. Answer: ", "{answer}"),
        ("{references}\nNow answer: {question} Answer: ", "{answer}"),
        ("{references}\nAfter reading the above, answer this question: {question} Answer: ", "{answer}"),
        ("{references}\nThen generate your answer to this question: {question} Answer: ", "{answer}"),
        ("Provide the answer for: {question}\nSupported by: {references}\nAnswer: ", "{answer}"),
        ("Given the references below, answer the question: {question}\nReferences: {references}\nAnswer: ", "{answer}"),
        ("Explore the references and answer: {question}\nReferences: {references}\nAnswer: ", "{answer}"),
        ("References available: {references}\nAfter reviewing the references, response to: {question}\nAnswer: ", "{answer}"),
        ("{references}\n\nRead these passages and answer the question: {question} Answer: ", "{answer}"),
        ("{references}\n\n{question}\n\nAnswer the question. Answer: ", "{answer}"),
        ("According to the references: {references}\n\nAnswer the question: {question}\n\nAnswer: ", "{answer}"),
    ],
    "conversational-qa-coqa": [
        ("{context}\n{history}\nAnswer the question: {questions} Answer: ", "{answers}"),
        ("Answer the questions at the end based on:\n{context}\n\n{questions}\n\nAnswer: ", "{answers}"),
        ("Given the passage\n{context}\nand previous dialogue history\n{history}\nAnswer the questions: {questions} Answer: ", "{answers}"),
        ("{context}\n\nWhat are the answers to these questions: {questions} Answer: ", "{answers}"),
        ("{context}\n\n{questions}\n\nGive me a numbered list of answers. Answer: ", "{answers}"),
        ("Read the article below, then answer the questions\n\n{context}\n\n{questions}\n\nAnswer: ", "{answers}"),
        ("Respond to the following questions in light of the provided context:\n{context}\nQuestions: {questions}\nAnswer: ", "{answers}"),
        ("In the context provided, answer the following questions:\n{context}\nQuestions: {questions}\nAnswer: ", "{answers}"),
        ("{context}\n\nAnswer this series of questions:\n\n{questions}\n\nAnswer: ", "{answers}"),
        ("After reading the article and previous dialogue history, answer the accompanying question:\nContext: {context}\nHistory: {history}\nQuestions: {questions}\nAnswer: ", "{answers}"),
        ("Make use of the article to answer the questions.\n\n{context}\n\n{questions}\n\nAnswer: ", "{answers}"),
        ("{context}\n\nBased on the article, answer the following list of questions.\n\n{questions}\n\nAnswer: ", "{answers}"),
    ],
    "conversational-qa-quac": [
        ("Extract the answer of {question} from the background\n\n{background}\n\nand context\n\n{context}\n\nwith previous dialogue history\n\n{history}\n\nAnswer: ", "{answers}"),
        ("{background}\n\n{context}\n\nTake a quote from it as the answer to the question: {question} Answer: ", "{answers}"),
        ("Which excerpt can be the answer to the question?\nBackground: {background}\nContext: {context}\nQuestion: {question}\nAnswer: ", "{answers}"),
        ("{background}\n\n{context}\n\nAnswer this: {question}, by extracting a quote from the background above. Answer: ", "{answers}"),
        ("Retrieve the response to {question} from the background and context provided\nBackground: {background}\nContext: {context}\nAnswer: ", "{answers}"),
        ("Select a relevant quote from the following background as the answer to: {question}\nBackground: {background}\nContext: {context}\nAnswer: ", "{answers}"),
        ("Consider the following background and previous dialogue history, then derive an answer to: {question}\nBackground: {background}\nContext: {context}\nHistory: {history}\nAnswer: ", "{answers}"),
        ("Background: {background}\nContext: {context}\nWithin the context provided, choose the quote that answers the following question: {question} Answer: ", "{answers}"),
        ("{background}\n{context}\nDelve into the background information about the previous dialogue history \"{history}\", then generate the response to: {question} Answer: ", "{answers}"),
        ("Identify the excerpt as the answer to the question at the end:\n{background}\n{context}\nQuestion: {question}\nAnswer: ", "{answers}"),
        ("Background: {background}\nContext: {context}\nQuestion: {question}\n\nAnswer: ", "{answers}"),
        ("{background}\n\n{context}\n\nHere is a question: {question}. Please answer it. Answer: ", "{answers}"),
    ],
    "general-retrieval-ms-marco": [
        ("Assess the relevance between the provided document:\n{document}\nand the query: \"{query}\". Respond with 'Yes' if the document is relevant to the query or 'No' if not. Response: ", "{judgment}"),
        ("Investigate the relationship between the document:\n{document}\nand query - {query}. Ascertain the document's relevance to the given query, providing a definitive response of 'Yes' if the document is relevant to the query or 'No' if not. Response: ", "{judgment}"),
        ("Explore the contents of the provided document:\n{document}\nFormulate a query that encapsulates the information presented. Return the generated query. Query: ", "{query}"),
        ("Delve into the information within the provided document:\n{document}\nGenerate a query that succinctly captures the essence of the document. Return the formulated query. Query: ", "{query}"),
        ("Consider a query \"{query}\" alongside two documents:\n{document}\nDecide which document is more relevant to the given query by providing the corresponding document identifier. Answer: ", "{identifier}"),
        ("Check a query: \"{query}\" in conjunction with two documents:\n{document}\neach with a unique identifier. Determine the document identifier corresponding to the more relevant document for the given query. Answer: ", "{identifier}"),
        ("Given a query:\"{query}\" and two documents:\n{document}\nHere is a hypothesis: the {num} document is more relevant to the given query. Determine that hypothesis by producing 'Yes' if the hypothesis is true or 'No' if it is false. Response: ", "{judgment}"),
        ("Evaluate the hypothesis suggesting that, given a query - \"{query}\" and two documents:\n{document}\nthe document labeled {num} is more relevant. Confirm or deny this hypothesis by responding with 'Yes' if the hypothesis is true or 'No' if it's false. Response: ", "{judgment}"),
        ("Here are some documents:\n{document}\nand a query \"{query}\", and each document is indicated by a number identifier. Please sort the documents in an order based on their relevance to the above query by returning an identifier list. Be careful to sort documents in order of their relevance to the query from highest to lowest. Result: ", "{identifier}"),
        ("Organize the some documents:\n{document}\naccording to their relevance to the provided query \"{query}\". Return the list of identifiers, indicating the order of decreasing relevance. Result: ", "{identifier}"),
        ("Here are some documents:\n{document}\nand a query \"{query}\", and each document is indicated by a number identifier. Here is an identifiers list:\n{identifier}\nDetermine if the list is ranked from highest to lowest by the relevance of the documents to the given query. If so, return 'Yes', otherwise 'No'. Answer: ", "{judgment}"),
        ("Examine a query:\"{query}\" alongside some documents:\n{document}\neach marked with a unique identifier. Utilizing the provided list of identifiers:\n{identifier}\nDetermine whether the list accurately ranks the documents from highest to lowest relevance to the given query, and respond with 'Yes' if so or 'No' if not. Response: ", "{judgment}")
    ],
    "biomedical-retrieval-trec-covid": [
        ("Document: {document}\n\nQuery: {query}\n\nAssess the relevance of the provided document in the context of the COVID-19-related query. Answer 'Yes' if the document explicitly addresses or pertains to the query, or 'No' if it is unrelated. Answer: ", "{judgment}"),
        ("Here is a document related to COVID-19:\n{document}\nand a corresponding query: \"{query}\". Evaluate the relevance between the document and the query. Provide your assessment by answering with either 'Yes' for relevance or 'No' for irrelevance. Answer: ", "{judgment}"),
        ("Given the document on COVID-19:\n{document}\nCreate a query that directly relates to its content. Query: ", "{query}"),
        ("Given the provided document on COVID-19:\n{document}\nFormulate a query that aligns with the information detailed in the document. Query: ", "{query}"),
        ("Given a query: \"{query}\" and two documents:\n{document}\nEach marked with a unique identifier and related to COVID-19, assess and identify which document is more closely related to the query. Respond with the identifier of the more relevant document. Response: ", "{identifier}"),
        ("Evaluate the relevance of two documents:\n{document}\nBoth concerning COVID-19, against the query: \"{query}\". Provide the identifier of the document that is more pertinent to the query and return the identifier. Result: ", "{identifier}"),
        ("Given the query: \"{query}\" and two documents related to COVID-19:\n{document}\nAssess the hypothesis that the document numbered {num} is more relevant to the query. Confirm or refute this hypothesis by responding with 'Yes' for agreement or 'No' for disagreement. Answer: ", "{judgment}"),
        ("For the two documents:\n{document}\nExamine the hypothesis stating that the {num} document has greater relevance to the specified query: \"{query}\". Conclude the assessment with either 'Yes' if the hypothesis is correct or 'No' if it is incorrect. Answer: ", "{judgment}"),
        ("Given several documents:\n{document}\neach pertaining to COVID-19, and a specific query: \"{query}\", organize the documents in order of relevance to the query. List the identifiers of these documents starting from the most relevant to the least relevant. Result: ", "{identifier}"),
        ("Rank the documents:\n{document}\nall related to COVID-19, in order of their relevance to the specified query: \"{query}\". The ranking should start with the most relevant document. Output this ranking as a list of the documents' identifiers, from highest to lowest relevance. Result: ", "{identifier}"),
        ("Given the COVID-19 documents:\n{document}\nand a query:\"{query}\", each document is labeled with a unique number. You are provided with a list of these numbers:\n{identifier}\nEvaluate if the documents in the list are ordered from the most to the least relevant in relation to the query. If the order is from highest to lowest relevance, return yes, otherwise return no. Answer: ", "{judgment}"),
        ("For the query:\"{query}\" and provided COVID-19 documents:\n{document}\neach with a unique numerical identifier, and a given list of these identifiers:\n{identifier}\n, determine if the documents are ranked in descending order of relevance to the query. Indicate your assessment by answering 'Yes' if this is true or 'No' if not. Answer: ", "{judgment}")
    ],
    "biomedical-retrieval-nfcorpus": [
        ("Assess the relevance of the medical document:\n{document}\nin relation to the search query \"{query}\". Determine if the document is relevant by responding with 'Yes' for relevance or 'No' for irrelevance. Answer: ", "{judgment}"),
        ("Assess the relevance of this medical document to a specific query.\nDocument:\n{document}\nQuery:\n\"{query}\"\nIs the document relevant to the query? Respond with 'Yes' for relevance or 'No' for irrelevance. Response: ", "{judgment}"),
        ("Create a search query that matches the context of the given medical document.\nDocument:\n{document}\nGenerate a query that accurately reflects the main themes or topics of the document. Query: ", "{query}"),
        ("Formulate a search query that closely relates to the content of the specified medical field document.\nDocument:\n{document}\nDesign a query that effectively captures the key information or themes presented in the document. Query: ", "{query}"),
        ("Assess which of the two medical field documents is more relevant to the provided query \"{query}\". Each document is presented with a unique identifier.\nDocuments:\n{document}\nIdentify and return the identifier of the document that best aligns with the query. Result: ", "{identifier}"),
        ("Evaluate which one of the two medical field documents is more pertinent to the search query \"{query}\". Each document has a unique identifier.\nDocuments:\n{document}\nSelect and return the identifier of the document that demonstrates greater relevance to the query. Result: ", "{identifier}"),
        ("Review the provided query \"{query}\" and two medical field documents:\n{document}\neach with a unique identifier. You are given a hypothesis:\n\"The document with identifier '{num}' is more relevant to the query.\"\nRespond with 'Yes' or 'No' to assess the accuracy of this hypothesis. Note that if the hypothesis is correct, return 'Yes', otherwise return 'No'. Answer: ", "{judgment}"),
        ("Considering the query \"{query}\" and two medical field documents:\n{document}\nexamine the hypothesis stating \"The document with identifier '{num}' is more relevant to the query.\" Determine the validity of this hypothesis and indicate your conclusion by responding with either 'Yes' or 'No'. Note that if the hypothesis is correct, return 'Yes', otherwise return 'No'. Answer: ", "{judgment}"),
        ("Arrange the given medical field documents:\n{document}\nin order of relevance to the specified query \"{query}\", with the most relevant document at the top and the least relevant at the bottom. Use their unique number identifiers to indicate the sequence of relevance. Result: ", "{identifier}"),
        ("Sort the provided medical field documents:\n{document}\nin a list according to their relevance to the query \"{query}\". Begin with the document that is most relevant and conclude with the least relevant. Use the respective number identifiers of each document to denote their order of relevance. Result: ", "{identifier}"),
        ("Assess the sequence of medical field documents:\n{document}\nin reference to the query \"{query}\", where each document has a number identifier. Given a list of these identifiers:\n{identifier}\nEvaluate if they are correctly ordered from most to least relevant in relation to the query. Answer with 'Yes' for correcness or 'No' for incorrectness. Answer: ", "{judgment}"),
        ("Given the query \"{query}\" and a set of medical field documents:\n{document}\neach assigned a unique identifier, and an existing list of these identifiers:\n{identifier}\nevaluate if the list accurately ranks the documents from most to least relevant in relation to the query. Answer with 'Yes' if so or 'No' if not. Answer: ", "{judgment}")
    ],
    "supporting-evidence-retrieval-nq": [
        ("Review the content of the document:\n{document}\nand ascertain its relevance to the topic: \"{query}\". Provide your determination by responding with either 'Yes' for relevance or 'No' for irrelevance. Result: ", "{judgment}"),
        ("Examine the given document:\n{document}\nand the query \"{query}\". You are presented with a statement: The document is relevant to the query. Assess the accuracy of this statement and respond with either 'Yes' or 'No' to indicate whether the judgment is correct or incorrect. Answer: ", "{judgment}"),
        ("Review the given document:\n{document}\nand create a search query that is closely related to the content of the document. Query: ", "{query}"),
        ("Examine the document:\n{document}\nand develop a search query that is directly related to the information contained within the document. Query: ", "{query}"),
        ("Evaluate the relevance of the provided query \"{query}\" to a pair of documents:\n{document}\neach identified separately. Determine which document is more relevant to the query and return the identifier of the more relevant document. Result: ", "{identifier}"),
        ("Analyze the query \"{query}\" along with two documents:\n{document}\neach with its identifier. Select the document identifier that is of greater relevance to the provided query. Result: ", "{identifier}"),
        ("Evaluate the query \"{query}\" and two documents:\n{document}\neach assigned a unique identifier. You are provided with a hypothesis: The document labeled as \"{num}\" is more relevant. Determine the correctness of this hypothesis and respond with 'Yes' for correctness or 'No' for incorrectness. Response: ", "{judgment}"),
        ("Assess the query \"{query}\" and the paired documents:\n{document}\nYou are presented with a hypothesis: The document labeled as \"{num}\" is more relevant to the query. Provide your judgment by responding with 'Yes' or 'No' to ascertain the accuracy of this hypothesis. 'Yes' means the hypothesis is correct, and 'No' means incorrect. Answer: ", "{judgment}"),
        ("Arrange the provided documents:\n{document}\nin accordance with their relevance to the specified query \"{query}\". Utilize number identifiers to denote the sequence of relevance, with the most relevant document at the top and the least relevant document at the end. Result: ", "{identifier}"),
        ("Evaluate the relevance of the given documents:\n{document}\nin relation to the provided query \"{query}\". Arrange them in descending order of relevance, using number identifiers for output, with the most relevant documents positioned at the top. Result: ", "{identifier}"),
        ("Examine the query \"{query}\" and the set of documents:\n{document}\neach distinguished by a unique identifier. Evaluate the provided identifier list \"{identifier}\" to determine if it correctly orders the documents from the highest to lowest relevance with respect to the specified query. If it is indeed in order of relevance from highest to lowest, return 'Yes', else return 'No'. Result: ", "{judgment}"),
        ("With the query \"{query}\" and a collection of documents:\n{document}\nwhere each document is assigned a unique identifier, and an associated list of these identifiers:\n{identifier}\nAssess whether the list accurately represents the order of documents from the most to least relevant to the query. If it does, return 'Yes', otherwise return 'No'. Answer: ", "{judgment}")
    ],
    "supporting-evidence-retrieval-fiqa": [
        ("Evaluate the financial document:\n{document}\nin the context of the query: \"{query}\". Determine if the document is relevant to the query and provide your judgment with 'Yes' for relevance or 'No' for irrelevance. Result: ", "{judgment}"),
        ("Examine the financial document:\n{document}\nand the query: \"{query}\". Determine whether the document is relevant to the query and indicate your judgment with either 'Yes' for relevance or 'No' for irrelevance. Answer: ", "{judgment}"),
        ("Review the financial document:\n{document}\nand create a query that is closely related to the information contained within the document. Result: ", "{query}"),
        ("Formulate a query that is directly related to the content of the financial document:\n{document}\nResult: ", "{query}"),
        ("Evaluate the relevance of the query: \"{query}\" and the pair of financial documents:\n{document}\neach assigned a unique identifier. Determine which document is more relevant to the provided query and specify its document identifier. Result: ", "{identifier}"),
        ("Evaluate the relevance of the query: \"{query}\" to the pair of financial documents:\n{document}\neach distinguished by an identifier. Clearly indicate which document is more relevant to the query by specifying its document identifier. Result: ", "{identifier}"),
        ("Analyze the query: \"{query}\" along with two financial documents:\n{document}\nYou are presented with a hypothesis: The {num} document is more relevant to the query. Assess the accuracy of this hypothesis and respond with either 'Yes' for accuracy or 'No' for inaccuracy. Response: ", "{judgment}"),
        ("Examine the connection between the query: \"{query}\" and the two financial documents:\n{document}\nGiven the hypothesis that the {num} document is more relevant, assess the accuracy of this hypothesis and provide your judgment by responding with 'Yes' if the hypothesis is true or 'No' if false. Response: ", "{judgment}"),
        ("Assess the relevance of the query: \"{query}\" to a set of financial documents:\n{document}\nGenerate a list of document identifiers, arranging them from the most relevant to the least relevant in relation to the query, and return the identifiers list. Result: ", "{identifier}"),
        ("Evaluate the relevance of the provided financial documents:\n{document}\nto the query: \"{query}\". Generate a list of document identifiers, arranging them in descending order to reflect their relevance to the provided query, and return the identifiers list. Result: ", "{identifier}"),
        ("Examine the relevance of the financial documents:\n{document}\nto the query: \"{query}\". Given the provided list of identifiers:\n{identifier}\nassess whether this list correctly orders the documents from the highest to lowest relevance, and respond with 'Yes' or 'No'. If it is indeed arranged this way, return 'Yes', otherwise return 'No'. Answer: ", "{judgment}"),
        ("Considering the query: \"{query}\" and a collection of financial documents:\n{document}\neach labeled with number identifiers, along with a list of identifiers:\n{identifier}\nEvaluate if the list accurately represents the order of documents from highest to lowest relevance to the provided query. Provide your judgment with either 'Yes' or 'No'. If the correlation is indeed highest to lowest, return 'Yes', otherwise return 'No'. Answer: ", "{judgment}")
    ],
    "supporting-evidence-retrieval-hotpot-qa": [
        ("Analyze the relationship between the document:\n{document}\nand the query: \"{query}\". Offer a definitive response by indicating whether they are relevant, and reply with either 'Yes' for relevance or 'No' for irrelevance. Reply: ", "{judgment}"),
        ("Provide a judgment regarding the relevance of the given document:\n{document}\nto the provided query: \"{query}\". State 'Yes' or 'No' based on their correlation. Return 'Yes' if relevant and 'No' if not. Answer: ", "{judgment}"),
        ("Generate a query that aligns with the information presented in the provided document:\n{document}\nQuery: ", "{query}"),
        ("Create a query that corresponds to the content presented in the provided document:\n{document}\nQuery: ", "{query}"),
        ("Compare the relevance of two documents:\n{document}\nto the provided query: \"{query}\". Identify the document with the higher relevance by specifying its identifier. Answer: ", "{identifier}"),
        ("Evaluate the relevance of the two documents:\n{document}\nin the context of the query: \"{query}\". Select the identifier of the document that is more relevant to the provided query based on their relevance. Answer: ", "{identifier}"),
        ("Here are two documents with their own identifiers:\n{document}\nAssess the correctness of the hypothesis proposing that document {num} is more relevant to the provided query: \"{query}\" than another document. Provide a clear response of 'Yes' if indeed more relevant or 'No' if not. Response: ", "{judgment}"),
        ("Given the query: \"{query}\" and two documents:\n{document}\nDetermine if document {num} is more relevant. Respond with 'Yes' if indeed more relevant or 'No' if not. Response: ", "{judgment}"),
        ("Rank the following documents in descending order of relevance to the query: \"{query}\"\n{document}\nProvide the list of identifiers. Result: ", "{identifier}"),
        ("Given the query: \"{query}\" and a list of documents:\n{document}\nSort the documents in descending order of relevance and return the resulting list of identifiers. Result: ", "{identifier}"),
        ("Given a set of documents: {document}, each with a unique identifier, and the list of identifiers: {identifier}, evaluate the hypothesis that this list ranks the documents in descending order of relevance to the query: \"{query}\". Provide a response of 'Yes' for correct hypothesis or 'No' for incorrect hypothesis. Result: ", "{judgment}"),
        ("Examine a query:\"{query}\" and some documents:\n{document}\neach with its own identifier. Given the list of identifiers:\n{identifier}\nDetermine whether the list accurately ranks the documents from highest to lowest relevance to the given query, and respond with 'Yes' if this is indeed the correct order or 'No' if not. Response: ", "{judgment}")
    ],
    "argument-retrieval-arguana": [
        ("Document:\n\n{document}\n\nQuery:\n\n{query}\n\nDetermine their relevance and return the judgment about the document's relevance to the query by responding with either 'Yes' for relevance or 'No' for irrelevance. Response: ", "{judgment}"),
        ("Assess the relevance between the document and query provided:\n{document}\nQuery:{query}Respond with 'Yes' if the document is relevant to the query, and 'No' if it is not. Response: ", "{judgment}"), 
        ("Document:\n{document}\nPlease formulate a query that is aligned with the document's argument. Query: ", "{query}"),
        ("Create a query that is relevant to the arguement in the document:\n{document}\n Query: ", "{query}"),
        ("Given a query \"{query}\" and two documents:\n{document}\nwith unique identifiers, decide which document's argument is more relevant to the query and output its corresponding identifier. Result: ", "{identifier}"),
        ("Evaluate the relevance of two documents:\n{document}\nto the provided query \"{query}\". Express the identifier of the document that is more relevant to the query. Result: ", "{identifier}"),
        ("Given a query \"{query}\" and two documents:\n{document}\nAssess the hypothesis that the {num} document's argument is more relevant to the query. Judge the hypothesis by choosing either 'Yes' if this hypothesis is true or 'No' if false. Answer: ", "{judgment}"),
        ("Here are two documents:\n{document}\nExamine the hypothesis that the argument in the {num} document is more relevant to the provided query \"{query}\". Return the judgment by choosing 'Yes' if the hypothesis is true or 'No' if not. Result: ", "{judgment}"),
        ("Rank some documents:\n{document}\n in descending order of relevance to the provided query: \"{query}\". Return the list of identifiers associated with each document in order. Result: ", "{identifier}"),
        ("Given a query \"{query}\" and some documents:\n{document}\nThese documents are identified by numbers. Please rerank these documents in descending order according to their relevance to the given query. Return a sorted list with the identifiers. Result: ", "{identifier}"),
        ("Here is a query: \"{query}\". There are some documents:\n{document}\nEach document has its unique identifier. Now, given an identifiers list {identifier}, determine if the order in the list accurately reflects the descending relevance of the documents to the provided query by responding with either 'Yes' if so or 'No' if not.", "{judgment}"),
        ("Provided a query: \"{query}\" and some documents:\n{document}\nEach document has a distinct identifier. Examine whether the order of the identifiers list {identifier} indicates the relevance of the documents related to the query from high to low by responding with either 'Yes' if the relevance is from high to low or 'No' if not.", "{judgment}")
    ],
    "argument-retrieval-touche": [
        ("Evaluate the relevance between the given document on controversial subjects:\n{document}\nand the query: \"{query}\", and provide a clear 'Yes' for relevance or 'No' for irrelevance judgment regarding their relevance. Answer: ", "{judgment}"),
        ("Determine the relevance between the given document on controversial subjects:\n{document}\nand the query: \"{query}\". Indicate the relevance with either 'Yes' for relevance or 'No' for irrelevance. Answer: ", "{judgment}"),
        ("Review the contents of the document on some controversial topics:\n{document}\nand formulate a query that covers the information presented. Query: ", "{query}"),
        ("Generate a query related to the provided document:\n{document}\nbased on the content within the document. Query: ", "{query}"),
        ("Given a query: \"{query}\" and two documents:\n{document}\neach with its unique identifier, determine which document is more relevant to the given query by providing the document identifier. Result: ", "{identifier}"),
        ("Compare the relevance of two documents:\n{document}\nto the query: \"{query}\", and specify the document identifier that has higher relevance. Result: ", "{identifier}"),
        ("Given a query:\"{query}\" and two documents:\n{document}\nConsider the hypothesis that the {num} document is more relevant to the query. Confirm or deny this hypothesis with a response of 'Yes' or 'No'. Return 'Yes' if confirm the hypothesis or 'No'. Answer: ", "{judgment}"),
        ("Evaluate the following hypothesis: Given two documents:\n{document}\n with distinct identifiers, the document labeled {num} is more relevant to the given query: \"{query}\". Provide a 'Yes' or 'No' response. If the hypothesis is correct, return 'Yes', else return 'No'. Response: ", "{judgment}"),
        ("Rerank some provided documents on a controversial topic:\n{document}\nbased on their relevance to the query \"{query}\". Return a list of identifiers in the order of descending relevance. Result: ", "{identifier}"),
        ("Sort the documents on a controversial topic:\n{document}\nbased on their relevance to the given query: \"{query}\", listing the identifiers in the order of decreasing relevance. Result: ", "{identifier}"),
        ("Examine a query: \"{query}\" alongside some documents:\n{document}\neach marked with a unique identifier. Given the provided list of identifiers:\n{identifier}\nDetermine whether the list accurately ranks the documents from highest to lowest relevance to the given query, and respond with 'Yes' if this correlation order is true or 'No' if not. Result: ", "{judgment}"),
        ("Assess the accuracy of the provided list of identifiers:\n{identifier}\nin ranking some documents:\n{document}\nfrom highest to lowest relevance to the given query: \"{query}\". Provide a 'Yes' or 'No' response. Notice if this sort is correct, return 'Yes', else return 'No'. Response: ", "{judgment}")
    ],
    "duplicate-question-retrieval-cqadupstack": [
        ("Evaluate the relevance between the given document on controversial subjects:\n{document}\nand the query: \"{query}\", and provide a clear 'Yes' for relevance or 'No' for irrelevance judgment regarding their relevance. Answer: ", "{judgment}"),
        ("Determine the relevance between the given document on controversial subjects:\n{document}\nand the query: \"{query}\". Indicate the relevance with either 'Yes' for relevance or 'No' for irrelevance. Response: ", "{judgment}"),
        ("Review the contents of the document on some controversial topics:\n{document}\nand formulate a query that covers the information presented. Query: ", "{query}"),
        ("Generate a query related to the provided document:\n{document}\nbased on the content within the document. Query: ", "{query}"),
        ("Given a query: \"{query}\" and two documents:\n{document}\neach with its unique identifier, determine which document is more relevant to the given query by providing the document identifier. Result: ", "{identifier}"),
        ("Compare the relevance of two documents:\n{document}\nto the query: \"{query}\", and specify the document identifier that has higher relevance. Result: ", "{identifier}"),
        ("Given a query: \"{query}\" and two documents:\n{document}\nConsider the hypothesis that the {num} document is more relevant to the query. Confirm or deny this hypothesis with a response of 'Yes' or 'No'. Return 'Yes' if confirm the hypothesis or 'No'. Answer: ", "{judgment}"),
        ("Evaluate the following hypothesis: Given two documents:\n{document}\nwith distinct identifiers, the document labeled {num} is more relevant to the given query:\"{query}\". Provide a 'Yes' or 'No' response. If the hypothesis is correct, return 'Yes', else return 'No'. Answer: ", "{judgment}"),
        ("Rerank some provided documents on a controversial topic:\n{document}\nbased on their relevance to the query \"{query}\". Return a list of identifiers in the order of descending relevance. Result: ", "{identifier}"),
        ("Sort the documents on a controversial topic:\n{document}\nbased on their relevance to the given query: \"{query}\", listing the identifiers in the order of decreasing relevance. Result: ", "{identifier}"),
        ("Examine a query: \"{query}\" alongside some documents:\n{document}\neach marked with a unique identifier. Given the provided list of identifiers:\n{identifier}\nDetermine whether the list accurately ranks the documents from highest to lowest relevance to the given query, and respond with 'Yes' if this correlation order is true or 'No' if not. Response: ", "{judgment}"),
        ("Assess the accuracy of the provided list of identifiers:\n{identifier}\nin ranking some documents:\n{document}\n from highest to lowest relevance to the given query: \"{query}\". Provide a 'Yes' or 'No' response. Notice if this sort is correct, return 'Yes', else return 'No'. Response: ", "{judgment}")
        ],
    "duplicate-question-retrieval-quora": [
        ("Determine the relevance between the document:\n{document}\nand the query: {query}. Judge whether they are related by responding with 'Yes' for relevance or 'No' for irrelevance. Response: ", "{judgment}"),
        ("Analyze the alignment of the document's content:\n{document}\nwith the query \"{query}\". Conclude with a 'Yes' if they align or a 'No' if they don't. Response: ", "{judgment}"),
        ("Inspect the document:\n{document}\nand derive a related question that matches its content. Formulate the related query. Query: ", "{query}"),
        ("Study the document:\n{document}\nand generate a query that reflects the information within. State the created query. Query: ", "{query}"),
        ("With a given query: \"{query}\" and two unique documents:\n{document}\nIdentify the document that aligns more closely with the query by stating its identifier. Result: ", "{identifier}"),
        ("Evaluate a query: \"{query}\" alongside two distinct documents:\n{document}\nChoose the document that is more relevant to the query and provide its identifier. Result: ", "{identifier}"),
        ("Assess if the document labeled {num} in the set of two documents:\n{document}\nis more relevant to the query: \"{query}\". Confirm or deny this with a 'Yes' or 'No' response. Response: ", "{judgment}"),
        ("Test the hypothesis that, among two documents:\n{document}\nthe one identified as {num} is more pertinent to the query: \"{query}\". Validate this with a 'Yes' if the hypothesis is true or 'No' if false answer. Response: ", "{judgment}"),
        ("Rank several documents:\n{document}\nby their relevance to the query: \"{query}\" in descending order. List their identifiers. Result: ", "{identifier}"),
        ("Organize various documents:\n{document}\naccording to their relevance to the query: {query}, listing them from most to least relevant. Result: ", "{identifier}"),
        ("Verify if the list of identifiers:\n{identifier}\ncorrectly ranks the documents:\n{document}\nin terms of their relevance to the query: \"{query}\" from highest to lowest. Provide a 'Yes' for accuracy or 'No' for inaccuracy. Result: ", "{judgment}"),
        ("Review the list of identifiers:\n{identifier}\nin relation to documents:\n{document}\nand a query: \"{query}\". Determine if the list accurately orders the documents from highest relevance to lowest relevance, answering with 'Yes' if so or 'No' if not. Answer: ", "{judgment}")
    ],
    "entity-retrieval-dbpedia": [
        ("Determine the relevance of the document:\n{document}\n to the query: \"{query}\". Conclude with 'Yes' for relevance or 'No' for irrelevance. Answer: ", "{judgment}"),
        ("Evaluate whether the document:\n{document}\n is relevant to the specified query: {query}. Provide a verdict expressed as 'Yes' if relevant or 'No' if irrelevant. Answer: ", "{judgment}"),
        ("Generate a query relevant to the document presented:\n{document}\nQuery: ", "{query}"),
        ("Create a query that corresponds to the given document:\n{document}\nQuery: ", "{query}"),
        ("Given a query: \"{query}\" and two documents:\n{document}\neach identified by a distinct number. Determine the document identifier for the one more relevant to the provided query. Result: ", "{identifier}"),
        ("Evaluate two documents:\n{document}\nwith unique identifiers in the context of a query: \"{query}\". Indicate which document is more relevant and provide its identifier. Result: ", "{identifier}"),
        ("Examine a hypothesis suggesting that, given a query \"{query}\" and two documents:\n{document}\nthe document labeled as {num} holds greater relevance. Judge this hypothesis by responding with 'Yes' if the hypothesis is true or 'No' if false. Answer: ", "{judgment}"),
        ("Analyse this hypothesis:\nIn the context of a query \"{query}\" and two documents:\n{document}\nthe {num} document has higher relevance about the query.\nDetermine this hypothesis with a response of 'Yes' if it is true or 'No' if it's false. Answer: ", "{judgment}"),
        ("Rank some documents:\n{document}\nbased on their relevance to the specified query \"{query}\". Return the list of identifiers in descending order. Result: ", "{identifier}"),
        ("Arrange some documents:\n{document}\nin descending order of relevance to the given query: {query}. Provide the identifier list with the most relevant first and the least relevant last. Result: ", "{identifier}"),
        ("Assess the ranking of some documents:\n{document}\nin relation to the provided query: \"{query}\". The given identifiers list is:\n{identifier}\nJudge whether the list is correctly ordered from highest to lowest relevance. Respond with either 'Yes' if the order is indeed that or 'No' if not. Result: ", "{judgment}"),
        ("Evaluate the set of documents:\n{document}\nconcerning the given query: \"{query}\". Check the list of identifiers:\n{identifier}\nDetermine the accuracy of the ranking by relevance from highest to lowest and reply with 'Yes' or 'No'. If it is sorted by relevance from highest to lowest, return 'Yes', else return 'No'. Result: ", "{judgment}")
    ],
    "article-retrieval-scidocs": [
        ("Determine the correlation between the provided literature-related document:\n{document}\nand the query: \"{query}\". Conclude if they are closely connected with a 'Yes' for relevance or 'No' for irrelevance. Response: ", "{judgment}"),
        ("Evaluate whether the scientific document:\n{document}\nis strongly relevant to the query: \"{query}\". Respond with 'Yes' if it is relevant or 'No' if it is not. Response: ", "{judgment}"),
        ("Examine the document:\n{document}\nand create a query that is derived from its contents. Query: ", "{query}"),
        ("Study the document:\n{document}\nand develop a query that reflects its content. Query: ", "{query}"),
        ("Given a query:\"{query}\" and two literature-related documents:\n{document}\neach with a unique identifier, identify which document is more relevant to the query by specifying its identifier. Result: ", "{identifier}"),
        ("Compare two documents:\n{document}\nagainst a query:\"{query}\" and decide which document, identified by its unique identifier, is more relevant. Result: ", "{identifier}"),
        ("Judge the hypothesis that for a given query:\"{query}\" and two scientific documents:\n{document}\nthe document labeled {num} is more relevant. Respond with 'Yes' for agreement or 'No' for disagreement. Response: ", "{judgment}"),
        ("Test the hypothesis that among two documents:\n{document}\nthe one marked as {num} is more relevant to the query:\"{query}\". Confirm or refute with 'Yes' or 'No'. Response: ", "{judgment}"),
        ("Rank the documents:\n{document}\nin order of their relevance to the query: {query}. List the identifiers starting with the most relevant document. Result: ", "{identifier}"),
        ("Sort the provided literature-related documents:\n{document}\nbased on how relevant they are to the query: \"{query}\". List the identifiers in descending order of relevance. Result: ", "{identifier}"),
        ("Evaluate if the given list of identifiers:\n{identifier}\ncorrectly ranks the documents:\n{document}\nin order of their relevance to the query: \"{query}\" from highest relevance to lowest relevance. Respond with 'Yes' for accuracy or 'No' for inaccuracy. Response: ", "{judgment}"),
        ("Review the ranking of documents:\n{document}\n by their relevance to the query:\"{query}\" using the provided list of identifiers:\n{identifier}\nConfirm the accuracy of the ranking with 'Yes' or 'No'. If the list is sorted from highest relevance to lowest relevance, return 'Yes', else return 'No'. Response: ", "{judgment}")
    ],
    "fact-retrieval-climate-fever": [
        ("Analyze the correlation between this document on the topic of climate change:\n{document}\nand the following query: {query}. Determine if the document is relevant to the query. Respond with 'Yes' for relevance or 'No' for irrelevance. Response: ", "{judgment}"),
        ("Evaluate the document's relevance to the query on climate change:\n{document}\nagainst this query: \"{query}\" by exploring their connection. Conclude with 'Yes' for relevance or 'No' for irrelevance. Response: ", "{judgment}"),
        ("Investigate the document on climate change:\n{document}\nand develop a query that aligns with its content. Query: ", "{query}"),
        ("Formulate a query that corresponds to the information in this climate change document:\n{document}\nQuery: ", "{query}"),
        ("Given this query:\"{query}\" and two climate change documents:\n{document}\neach with a unique identifier, identify which document aligns more closely with the query by indicating the document's identifier. Result: ", "{identifier}"),
        ("Compare the relevance of two climate change documents:\n{document}\nto this query: \"{query}\" and identify the document with greater relevance by its identifier. Result: ", "{identifier}"),
        ("With a query: \"{query}\" and two documents on climate change:\n{document}\nevaluate whether the document labeled {num} is more relevant to the query. Answer with 'Yes' if it is more relevant or 'No' if not. Answer: ", "{judgment}"),
        ("Test the hypothesis that in two documents:\n{document}\nthe one labeled {num} is more relevant to the query: \"{query}\". Confirm or deny this with 'Yes' or 'No'. Result: ", "{judgment}"),
        ("Rerank these climate change documents:\n{document}\nby their relevance to the query: \"{query}\" and list the identifiers. Rank from most to least relevant. Result: ", "{identifier}"),
        ("Sort these climate change documents:\n{document}\n based on their relevance to the query: \"{query}\". List the identifiers in order of relevance, starting with the most relevant and ending with the most irrelevant. Result: ", "{identifier}"),
        ("Review this query: \"{query}\" and the climate change documents:\n{document}\nConfirm if the provided list of identifiers: {identifier} correctly ranks the documents in order of relevance to the query from highest to lowest. Respond with 'Yes' if so or 'No' if not. Response: ", "{judgment}"),
        ("Evaluate if the given list of identifiers:\n{identifier}\naccurately ranks these documents:\n{document}\nin order of relevance to the query: \"{query}\". Answer with 'Yes' if it's in order of relevance from highest to lowest or 'No' if not. Answer: ", "{judgment}")
    ],
    "fact-retrieval-fever": [
        ("Assess the relationship between the given document:\n{document}\nand the query: \"{query}\" to determine if the document is relevant. Answer with 'Yes' for relevance or 'No' for irrelevance. Answer: ", "{judgment}"),
        ("Review the provided document:\n{document}\nin relation to the query: \"{query}\" and decide if there is relevance. Respond with 'Yes' if it is relevant or 'No' if it is not. Response: ", "{judgment}"),
        ("Using the content of the provided document:\n{document}\nGenerate a query that closely aligns with the document's subject. Query: ", "{query}"),
        ("Develop a query that is in line with the subject matter of the provided document:\n{document}\nQuery: ", "{query}"),
        ("Evaluate two documents:\n{document}\nagainst a given query: \"{query}\" and identify the document that is more relevant by its identifier. Result: ", "{identifier}"),
        ("With a query \"{query}\" and two documents:\n{document}\nascertain which document is more relevant and provide its identifier. Result: ", "{identifier}"),
        ("Test the hypothesis regarding the relevance of two documents:\n{document}\nto a query \"{query}\", determining if the document labeled {num} is more pertinent. Respond with 'Yes' if the hypothesis is true or 'No' if false. Response: ", "{judgment}"),
        ("Assess the hypothesis that, given a query:\"{query}\" and two documents:\n{document}\nthe document labeled {num} is more relevant. Provide your judgment with 'Yes' if the hypothesis is correct or 'No' if not. Result: ", "{judgment}"),
        ("Rank a set of documents:\n{document}\nby their relevance to a query: \"{query}\". List their identifiers in order of decreasing relevance. Result: ", "{identifier}"),
        ("Organize a collection of documents:\n{document}\nbased on their relevance to the query: \"{query}\", and list them in descending order of relevance. Result: ", "{identifier}"),
        ("Verify if the list of identifiers:\n{identifier}\naccurately represents the ranking of documents:\n{document}\nin terms of their relevance to the query \"{query}\" from the highest relevance to the lowest relevance. Answer with 'Yes' for accuracy or 'No' for inaccuracy. Answer: ", "{judgment}"),
        ("Review a list of identifiers:\n{identifier}\nalongside documents:\n{document}\nand a query: {query}. Assess if the list correctly ranks the documents in terms of relevance from high to low according to the query and respond with 'Yes' if so or 'No' if not. Answer: ", "{judgment}")
    ],
    "fact-retrieval-scifact": [
        ("Assess the relevance between the scientific document:\n{document}\nand query: \"{query}\", and state 'Yes' or 'No' to reflect the relevance judgment. Answer 'Yes' for relevance and 'No' for irrelevance. Answer: ", "{judgment}"),
        ("Determine the relevance of the given scientific document:\n{document}\nto the query: \"{query}\". Respond with 'Yes' or 'No' to indicate relevance. If they are relevant, return 'Yes', else return 'No'. Answer: ", "{judgment}"),
        ("Generate a query that aligns with the key information in the given scientific document:\n{document}\nQuery: ", "{query}"),
        ("Return a query that reflects the main content of the supplied scientific document:\n{document}\nQuery: ", "{query}"),
        ("Analyze the relevance of two scientific documents:\n{document}\nto the query: \"{query}\" and identify the more relevant document by its identifier. Result: ", "{identifier}"),
        ("Compare the relevance of two scientific documents:\n{document}\nagainst the query: {query} and specify the identifier of the more relevant document. Result: ", "{identifier}"),
        ("For two scientific documents:\n{document}\nEvaluate the hypothesis that the document labeled {num} is more relevant to the provided query: \"{query}\" than the other. Respond with 'Yes' if the hypothesis is correct or 'No' if incorrect. Response: ", "{judgment}"),
        ("Hypothesize that between two scientific documents:\n{document}\n and a query: {query}, the document labeled {num} is more relevant. Confirm or refute with 'Yes' or 'No'. Result: ", "{judgment}"),
        ("Order the provided scientific documents:\n{document}\n based on their relevance to the query: \"{query}\", from most to least relevant. Only output a list of identifiers. Result: ", "{identifier}"),
        ("Organize some documents:\n{document}\nby their relevance to the provided query: {query}, listing the identifiers from highest to lowest relevance. Result: ", "{identifier}"),
        ("Here are some documents:\n{document}\nwith unique identifiers and a query: \"{query}\". Given an identifier list:\n{identifier}\nAssess the accuracy of the list in ranking those documents from highest to lowest relevance to the provided query. Provide a conclusive 'Yes' or 'No' judgment. If indeed it's ranked from highest to lowest by correlation, return 'Yes', else return 'No'. Result: ", "{judgment}"),
        ("Examine a query: \"{query}\" alongside some documents:\n{document}\neach with its own identifier. Give a list of identifiers:\n{identifier}\nDetermine if the list accurately ranks the documents from the most to the least relevant to the given query, and reply with 'Yes' if the list given is in the correct order or 'No' if not. Reply: ", "{judgment}")
    ]
}